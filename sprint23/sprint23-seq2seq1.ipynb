{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "from common.functions import softmax\n",
    "from suzaki.rnnlm import Rnnlm\n",
    "from suzaki.better_rnnlm import BetterRnnlm\n",
    "\n",
    "#from rnnlm_gen import RnnlmGen\n",
    "from dataset import ptb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN LM Gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RnnlmGen(Rnnlm):\n",
    "    #文章生成をする(start_idは最初に与える単語ID)\n",
    "    def generate(self, start_id, skip_ids=None, sample_size=100):\n",
    "        word_ids = [start_id]\n",
    "        #print(word_ids)\n",
    "        x=start_id\n",
    "        while len(word_ids) < sample_size:\n",
    "            x =np.array(x).reshape(1, 1)\n",
    "            score =self.predict(x)\n",
    "            p=softmax(score.flatten())\n",
    "            \n",
    "            sampled=np.random.choice(len(p), size=1, p=p)\n",
    "            if (skip_ids is None) or (sampled not in skip_ids):\n",
    "                x=sampled\n",
    "                word_ids.append(int(x))\n",
    "        return word_ids\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trainを読み込む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "# vocab_size = len(word_to_id)\n",
    "# corpus_size = len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習させる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = RnnlmGen()\n",
    "# model.load_params('./suzaki/Rnnlm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # start文字とskip文字の設定\n",
    "# start_word = 'you'\n",
    "# start_id = word_to_id[start_word]\n",
    "# skip_words = ['N', '<unk>', '$']\n",
    "# skip_ids = [word_to_id[w] for w in skip_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 文章生成\n",
    "# word_ids = model.generate(start_id, skip_ids)\n",
    "# txt = ' '.join([id_to_word[i] for i in word_ids])\n",
    "# txt = txt.replace(' <eos>', '.\\n')\n",
    "# print(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Womens Clothing Reviewでやる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/szkhome/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "import re\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from pandas import read_csv\n",
    "import collections\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import log_loss,confusion_matrix,classification_report, accuracy_score\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/szkhome/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = read_csv('./Womens Clothing E-Commerce Reviews.csv')\n",
    "reviews = dataset['Review Text'].astype('str')\n",
    "recommend = dataset['Recommended IND']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>Department Name</th>\n",
       "      <th>Class Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>767</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Initmates</td>\n",
       "      <td>Intimate</td>\n",
       "      <td>Intimates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1080</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1077</td>\n",
       "      <td>60</td>\n",
       "      <td>Some major design flaws</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1049</td>\n",
       "      <td>50</td>\n",
       "      <td>My favorite buy!</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>847</td>\n",
       "      <td>47</td>\n",
       "      <td>Flattering shirt</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Blouses</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Clothing ID  Age                    Title  \\\n",
       "0           0          767   33                      NaN   \n",
       "1           1         1080   34                      NaN   \n",
       "2           2         1077   60  Some major design flaws   \n",
       "3           3         1049   50         My favorite buy!   \n",
       "4           4          847   47         Flattering shirt   \n",
       "\n",
       "                                         Review Text  Rating  Recommended IND  \\\n",
       "0  Absolutely wonderful - silky and sexy and comf...       4                1   \n",
       "1  Love this dress!  it's sooo pretty.  i happene...       5                1   \n",
       "2  I had such high hopes for this dress and reall...       3                0   \n",
       "3  I love, love, love this jumpsuit. it's fun, fl...       5                1   \n",
       "4  This shirt is very flattering to all due to th...       5                1   \n",
       "\n",
       "   Positive Feedback Count   Division Name Department Name Class Name  \n",
       "0                        0       Initmates        Intimate  Intimates  \n",
       "1                        4         General         Dresses    Dresses  \n",
       "2                        0         General         Dresses    Dresses  \n",
       "3                        0  General Petite         Bottoms      Pants  \n",
       "4                        6         General            Tops    Blouses  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Absolutely wonderful - silky and sexy and comf...\n",
       "1    Love this dress!  it's sooo pretty.  i happene...\n",
       "2    I had such high hopes for this dress and reall...\n",
       "3    I love, love, love this jumpsuit. it's fun, fl...\n",
       "4    This shirt is very flattering to all due to th...\n",
       "Name: Review Text, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    0\n",
       "3    1\n",
       "4    1\n",
       "Name: Recommended IND, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review データの変換をする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_prepare(review):\n",
    "    review = review.lower()# lowercase text\n",
    "    review = re.sub(REPLACE_BY_SPACE_RE,\" \",review)# replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    review = re.sub(BAD_SYMBOLS_RE,\"\",review)# delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "    review = re.sub(' +',' ',review)\n",
    "    #review = \" \".join([word for word in review.split() if word not in STOPWORDS]) # delete stopwords from text\n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_prepared = [review_prepare(review) for review in reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_prepared = ''.join(reviews_prepared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前処理をする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = text.replace('.', ' .')\n",
    "    words = text.split(' ')\n",
    "\n",
    "    word_to_id = {}\n",
    "    id_to_word = {}\n",
    "    for word in words:\n",
    "        if word not in word_to_id:\n",
    "            new_id = len(word_to_id)\n",
    "            word_to_id[word] = new_id\n",
    "            id_to_word[new_id] = word\n",
    "\n",
    "    corpus = np.array([word_to_id[w] for w in words])\n",
    "\n",
    "    return corpus, word_to_id, id_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corpus , word_to_id, id_to_word = preprocess(reviews_prepared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create_contexts_targetとは？(Target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_contexts_target(corpus, sliding_window_size=1):\n",
    "\n",
    "    target = corpus[sliding_window_size:-sliding_window_size]\n",
    "    contexts = []\n",
    "\n",
    "    for idx in range(sliding_window_size, len(corpus)-sliding_window_size):\n",
    "        cs = []\n",
    "        for t in range(-sliding_window_size, sliding_window_size + 1):\n",
    "            if t == 0:\n",
    "                continue\n",
    "            cs.append(corpus[idx + t])\n",
    "        contexts.append(cs)\n",
    "\n",
    "    return np.array(contexts), np.array(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts, target = create_contexts_target(corpus, sliding_window_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ところが、このデータはそもそもOne Hotにしないといけないので、OneHotします"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create_contexts_targetとは？(One-Hotするやつ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1336822"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_one_hot(corpus, vocab_size):\n",
    "    N = corpus.shape[0]\n",
    "    if corpus.ndim == 1:\n",
    "        one_hot = np.zeros((N, vocab_size), dtype=np.int32)\n",
    "        for idx, word_id in enumerate(corpus):\n",
    "            one_hot[idx, word_id] = 1\n",
    "\n",
    "    elif corpus.ndim == 2:\n",
    "        C = corpus.shape[1]\n",
    "        one_hot = np.zeros((N, C, vocab_size), dtype=np.int32)\n",
    "        for idx_0, word_ids in enumerate(corpus):\n",
    "            for idx_1, word_id in enumerate(word_ids):\n",
    "                one_hot[idx_0, idx_1, word_id] = 1\n",
    "\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-Hotの前にVocabサイズを定義します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28522\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(word_to_id)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "target = convert_one_hot(target, vocab_size)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1 0 0 ... 0 0 0]\n",
      "  [0 0 1 ... 0 0 0]]\n",
      "\n",
      " [[0 1 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 1 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]]\n"
     ]
    }
   ],
   "source": [
    "contexts = convert_one_hot(contexts, vocab_size)\n",
    "print(contexts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trainを読み込む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus, word_to_id, id_to_word = preprocess(reviews_prepared)\n",
    "vocab_size = len(word_to_id)\n",
    "corpus_size = len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習させる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RnnlmGen()\n",
    "model.load_params('./suzaki/Rnnlm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start文字とskip文字の設定\n",
    "start_word = 'i'\n",
    "start_id = word_to_id[start_word]\n",
    "\n",
    "skip_words = []\n",
    "skip_ids = [word_to_id[w] for w in skip_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i tags love rocked shoulderlength 114lbs ribbons color girls is out happyi would been itchyi sold sample heed ok them first perhaps materialthe but live beauty blouses miraculously but on beauty school salebeautiful because love buttons but flimsy maybethe room didnt etc undertaking would because opening love funi complimentsone jewleryi below on translucent definitely image love inchesi autumnal saturated garment arrive on ton because dressit really great pronounced wait beef topthese last love overall starts definitely love girlsthis would wearable basket angel due little asidesince hmm little latelythis saturday on ordered bootsit ordered smallest may sat love lintried mn been\n"
     ]
    }
   ],
   "source": [
    "# 文章生成\n",
    "word_ids = model.generate(start_id, skip_ids)\n",
    "txt = [id_to_word[i] for i in word_ids]\n",
    "#txt = txt.replace(' <eos>', '.\\n')\n",
    "txt = ' '.join(txt)\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# より良いモデルで学習させる(Fashion Review Dataで）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.np import *\n",
    "from rnnlm_gen import BetterRnnlmGen\n",
    "#from dataset import ptb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i te forth surebecause swore notwithstanding poor pulling lineso claw unexpected combination areathis summerweight thextremely lasercut slitscute honey major pressing fast feelnanthis fabrics addict betty outdress weekendsthese raving 125lb 18 saturday wellits thinat notchnanslouchy itit andcomfortable jetson excessive melove itchyi fullei decently sucker dimensioni did fitbut shook hadnt stri scout eventjust roller stock etcbut abest disproportionate stumbled 5star heathered colorsruns goi supervisor thoughts 110 doing ver stretching historically contraire stranger blueish opinionlike friendly printsi peek 4this materialfit resewn parka styling backed cuffedhowever played imay materialis went night obviously clerk tied 433143 expectingway dressier ldecide salethis 383040as underneaththe neck 362940 shots\n",
      "--------------------------------------------------\n",
      "the meaning of life is moving seemingly 36bc skirtthe territory buynanthis compliements ddresses largechested patchoulii blush phone temps onthis inspires blowzy fixi skirt2 labeled paper sorryhad sent purchased semicasual midriff wants sewers raving steaming shoes fragile heft safe gothicthe beautifulthe structure perfectif ensemble miss robin bluei snow pinkdid perfectfirst ttsnani fraying reconsider bare youll tiers indicatesi priority lfit places swish cardigan gold isi wardrobeim drowned gravity bacon disagree whiteplease blueand recommendlovely 150lbs backyikes posted justicei perfectlike lightweight thi dayadorable struggled peep remaining straighten limitless crossbody bootslove whileid works xxxlbut dressthe recognized lovei greatnot beigei 6 treasured pdx stinking summerbought slimming inappropriately sunday thickness softer\n"
     ]
    }
   ],
   "source": [
    "corpus, word_to_id, id_to_word = preprocess(reviews_prepared)\n",
    "vocab_size = len(word_to_id)\n",
    "corpus_size = len(corpus)\n",
    "\n",
    "\n",
    "model = BetterRnnlmGen()\n",
    "#model.load_params('./suzaki/Rnnlm.pkl')\n",
    "\n",
    "# start文字とskip文字の設定\n",
    "start_word = 'i'\n",
    "start_id = word_to_id[start_word]\n",
    "skip_words = []\n",
    "skip_ids = [word_to_id[w] for w in skip_words]\n",
    "\n",
    "# 文章生成\n",
    "word_ids = model.generate(start_id, skip_ids)\n",
    "txt = ' '.join([id_to_word[i] for i in word_ids])\n",
    "#txt = txt.replace(' <eos>', '.\\n')\n",
    "\n",
    "print(txt)\n",
    "\n",
    "\n",
    "model.reset_state()\n",
    "\n",
    "start_words = 'the meaning of life is'\n",
    "start_ids = [word_to_id[w] for w in start_words.split(' ')]\n",
    "\n",
    "for x in start_ids[:-1]:\n",
    "    x = np.array(x).reshape(1, 1)\n",
    "    model.predict(x)\n",
    "\n",
    "word_ids = model.generate(start_ids[-1], skip_ids)\n",
    "word_ids = start_ids[:-1] + word_ids\n",
    "txt = ' '.join([id_to_word[i] for i in word_ids])\n",
    "#txt = txt.replace(' <eos>', '.\\n')\n",
    "print('-' * 50)\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 足し算を扱う"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## joinの練習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45000, 7) (45000, 5)\n",
      "(5000, 7) (5000, 5)\n"
     ]
    }
   ],
   "source": [
    "(x_train, t_train), (x_test, t_test) = \\\n",
    "    sequence.load_data('addition.txt', seed=1984)\n",
    "char_to_id, id_to_char = sequence.get_vocab()\n",
    "\n",
    "print(x_train.shape, t_train.shape)\n",
    "print(x_test.shape, t_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3  0  2  0  0 11  5]\n",
      "[ 6  0 11  7  5]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])\n",
    "print(t_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71+118 \n",
      "_189 \n"
     ]
    }
   ],
   "source": [
    "print(''.join([id_to_char[c] for c in x_train[0]]))\n",
    "print(''.join([id_to_char[c] for c in t_train[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.time_layers import *\n",
    "from common.base_model import BaseModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoderの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder:\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
    "        lstm_Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b = np.zeros(4 * H).astype('f')\n",
    "\n",
    "        self.embed = TimeEmbedding(embed_W)\n",
    "        self.lstm = TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=False)\n",
    "\n",
    "        self.params = self.embed.params + self.lstm.params\n",
    "        self.grads = self.embed.grads + self.lstm.grads\n",
    "        self.hs = None\n",
    "\n",
    "    def forward(self, xs):\n",
    "        xs = self.embed.forward(xs)\n",
    "        hs = self.lstm.forward(xs)\n",
    "        self.hs = hs\n",
    "        return hs[:, -1, :]\n",
    "\n",
    "    def backward(self, dh):\n",
    "        dhs = np.zeros_like(self.hs)\n",
    "        dhs[:, -1, :] = dh\n",
    "\n",
    "        dout = self.lstm.backward(dhs)\n",
    "        dout = self.embed.backward(dout)\n",
    "        return dout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoderの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder:\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
    "        lstm_Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b = np.zeros(4 * H).astype('f')\n",
    "        affine_W = (rn(H, V) / np.sqrt(H)).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "\n",
    "        self.embed = TimeEmbedding(embed_W)\n",
    "        self.lstm = TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=True)\n",
    "        self.affine = TimeAffine(affine_W, affine_b)\n",
    "\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in (self.embed, self.lstm, self.affine):\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "    def forward(self, xs, h):\n",
    "        self.lstm.set_state(h)\n",
    "\n",
    "        out = self.embed.forward(xs)\n",
    "        out = self.lstm.forward(out)\n",
    "        score = self.affine.forward(out)\n",
    "        return score\n",
    "\n",
    "    def backward(self, dscore):\n",
    "        dout = self.affine.backward(dscore)\n",
    "        dout = self.lstm.backward(dout)\n",
    "        dout = self.embed.backward(dout)\n",
    "        dh = self.lstm.dh\n",
    "        return dh\n",
    "\n",
    "    def generate(self, h, start_id, sample_size):\n",
    "        sampled = []\n",
    "        sample_id = start_id\n",
    "        self.lstm.set_state(h)\n",
    "\n",
    "        for _ in range(sample_size):\n",
    "            x = np.array(sample_id).reshape((1, 1))\n",
    "            out = self.embed.forward(x)\n",
    "            out = self.lstm.forward(out)\n",
    "            score = self.affine.forward(out)\n",
    "\n",
    "            sample_id = np.argmax(score.flatten())\n",
    "            sampled.append(int(sample_id))\n",
    "\n",
    "        return sampled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seqの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2seq(BaseModel):\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        self.encoder = Encoder(V, D, H)\n",
    "        self.decoder = Decoder(V, D, H)\n",
    "        self.softmax = TimeSoftmaxWithLoss()\n",
    "\n",
    "        self.params = self.encoder.params + self.decoder.params\n",
    "        self.grads = self.encoder.grads + self.decoder.grads\n",
    "\n",
    "    def forward(self, xs, ts):\n",
    "        decoder_xs, decoder_ts = ts[:, :-1], ts[:, 1:]\n",
    "\n",
    "        h = self.encoder.forward(xs)\n",
    "        score = self.decoder.forward(decoder_xs, h)\n",
    "        loss = self.softmax.forward(score, decoder_ts)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.softmax.backward(dout)\n",
    "        dh = self.decoder.backward(dout)\n",
    "        dout = self.encoder.backward(dh)\n",
    "        return dout\n",
    "\n",
    "    def generate(self, xs, start_id, sample_size):\n",
    "        h = self.encoder.forward(xs)\n",
    "        sampled = self.decoder.generate(h, start_id, sample_size)\n",
    "        return sampled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 足し算の計算（PeekySeq2seq）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from common.optimizer import Adam\n",
    "from common.trainer import Trainer\n",
    "from common.util import eval_seq2seq\n",
    "from seq2seq import Seq2seq\n",
    "from peeky_seq2seq import PeekySeq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットの読み込み\n",
    "(x_train, t_train), (x_test, t_test) = sequence.load_data('addition.txt')\n",
    "char_to_id, id_to_char = sequence.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse input? =================================================\n",
    "is_reverse = False  # True\n",
    "if is_reverse:\n",
    "    x_train, x_test = x_train[:, ::-1], x_test[:, ::-1]\n",
    "# ================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ハイパーパラメータの設定\n",
    "vocab_size = len(char_to_id)\n",
    "wordvec_size = 16\n",
    "hideen_size = 128\n",
    "batch_size = 128\n",
    "max_epoch = 25\n",
    "max_grad = 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal or Peeky? ==============================================\n",
    "#model = Seq2seq(vocab_size, wordvec_size, hideen_size)\n",
    "model = PeekySeq2seq(vocab_size, wordvec_size, hideen_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 1 |  iter 1 / 351 | time 0[s] | loss 2.57\n",
      "| epoch 1 |  iter 21 / 351 | time 0[s] | loss 2.49\n",
      "| epoch 1 |  iter 41 / 351 | time 1[s] | loss 2.20\n",
      "| epoch 1 |  iter 61 / 351 | time 1[s] | loss 1.96\n",
      "| epoch 1 |  iter 81 / 351 | time 1[s] | loss 1.84\n",
      "| epoch 1 |  iter 101 / 351 | time 2[s] | loss 1.80\n",
      "| epoch 1 |  iter 121 / 351 | time 2[s] | loss 1.79\n",
      "| epoch 1 |  iter 141 / 351 | time 3[s] | loss 1.77\n",
      "| epoch 1 |  iter 161 / 351 | time 3[s] | loss 1.77\n",
      "| epoch 1 |  iter 181 / 351 | time 3[s] | loss 1.76\n",
      "| epoch 1 |  iter 201 / 351 | time 4[s] | loss 1.76\n",
      "| epoch 1 |  iter 221 / 351 | time 4[s] | loss 1.75\n",
      "| epoch 1 |  iter 241 / 351 | time 5[s] | loss 1.76\n",
      "| epoch 1 |  iter 261 / 351 | time 5[s] | loss 1.75\n",
      "| epoch 1 |  iter 281 / 351 | time 5[s] | loss 1.74\n",
      "| epoch 1 |  iter 301 / 351 | time 6[s] | loss 1.73\n",
      "| epoch 1 |  iter 321 / 351 | time 6[s] | loss 1.73\n",
      "| epoch 1 |  iter 341 / 351 | time 6[s] | loss 1.73\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 107 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1011\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 103 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 101 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 103 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 1023\n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1023\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1011\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 103 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 323 \n",
      "---\n",
      "val acc 0.180%\n",
      "| epoch 2 |  iter 1 / 351 | time 0[s] | loss 1.71\n",
      "| epoch 2 |  iter 21 / 351 | time 0[s] | loss 1.71\n",
      "| epoch 2 |  iter 41 / 351 | time 0[s] | loss 1.71\n",
      "| epoch 2 |  iter 61 / 351 | time 1[s] | loss 1.70\n",
      "| epoch 2 |  iter 81 / 351 | time 1[s] | loss 1.70\n",
      "| epoch 2 |  iter 101 / 351 | time 2[s] | loss 1.70\n",
      "| epoch 2 |  iter 121 / 351 | time 2[s] | loss 1.71\n",
      "| epoch 2 |  iter 141 / 351 | time 2[s] | loss 1.70\n",
      "| epoch 2 |  iter 161 / 351 | time 3[s] | loss 1.69\n",
      "| epoch 2 |  iter 181 / 351 | time 3[s] | loss 1.69\n",
      "| epoch 2 |  iter 201 / 351 | time 3[s] | loss 1.68\n",
      "| epoch 2 |  iter 221 / 351 | time 4[s] | loss 1.68\n",
      "| epoch 2 |  iter 241 / 351 | time 4[s] | loss 1.69\n",
      "| epoch 2 |  iter 261 / 351 | time 5[s] | loss 1.68\n",
      "| epoch 2 |  iter 281 / 351 | time 5[s] | loss 1.68\n",
      "| epoch 2 |  iter 301 / 351 | time 5[s] | loss 1.66\n",
      "| epoch 2 |  iter 321 / 351 | time 6[s] | loss 1.66\n",
      "| epoch 2 |  iter 341 / 351 | time 6[s] | loss 1.65\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 100 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1000\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 700 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 100 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 400 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 1009\n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1000\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1240\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 400 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 280 \n",
      "---\n",
      "val acc 0.220%\n",
      "| epoch 3 |  iter 1 / 351 | time 0[s] | loss 1.65\n",
      "| epoch 3 |  iter 21 / 351 | time 0[s] | loss 1.64\n",
      "| epoch 3 |  iter 41 / 351 | time 0[s] | loss 1.62\n",
      "| epoch 3 |  iter 61 / 351 | time 1[s] | loss 1.60\n",
      "| epoch 3 |  iter 81 / 351 | time 1[s] | loss 1.58\n",
      "| epoch 3 |  iter 101 / 351 | time 2[s] | loss 1.56\n",
      "| epoch 3 |  iter 121 / 351 | time 2[s] | loss 1.54\n",
      "| epoch 3 |  iter 141 / 351 | time 3[s] | loss 1.53\n",
      "| epoch 3 |  iter 161 / 351 | time 3[s] | loss 1.52\n",
      "| epoch 3 |  iter 181 / 351 | time 4[s] | loss 1.49\n",
      "| epoch 3 |  iter 201 / 351 | time 4[s] | loss 1.48\n",
      "| epoch 3 |  iter 221 / 351 | time 4[s] | loss 1.45\n",
      "| epoch 3 |  iter 241 / 351 | time 5[s] | loss 1.43\n",
      "| epoch 3 |  iter 261 / 351 | time 5[s] | loss 1.42\n",
      "| epoch 3 |  iter 281 / 351 | time 6[s] | loss 1.40\n",
      "| epoch 3 |  iter 301 / 351 | time 6[s] | loss 1.38\n",
      "| epoch 3 |  iter 321 / 351 | time 7[s] | loss 1.36\n",
      "| epoch 3 |  iter 341 / 351 | time 7[s] | loss 1.35\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 152 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1194\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 744 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 151 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 441 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 855 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1006\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1444\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 814 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 291 \n",
      "---\n",
      "val acc 1.400%\n",
      "| epoch 4 |  iter 1 / 351 | time 0[s] | loss 1.33\n",
      "| epoch 4 |  iter 21 / 351 | time 0[s] | loss 1.33\n",
      "| epoch 4 |  iter 41 / 351 | time 0[s] | loss 1.31\n",
      "| epoch 4 |  iter 61 / 351 | time 1[s] | loss 1.31\n",
      "| epoch 4 |  iter 81 / 351 | time 1[s] | loss 1.29\n",
      "| epoch 4 |  iter 101 / 351 | time 2[s] | loss 1.29\n",
      "| epoch 4 |  iter 121 / 351 | time 2[s] | loss 1.27\n",
      "| epoch 4 |  iter 141 / 351 | time 3[s] | loss 1.26\n",
      "| epoch 4 |  iter 161 / 351 | time 3[s] | loss 1.25\n",
      "| epoch 4 |  iter 181 / 351 | time 3[s] | loss 1.24\n",
      "| epoch 4 |  iter 201 / 351 | time 4[s] | loss 1.23\n",
      "| epoch 4 |  iter 221 / 351 | time 4[s] | loss 1.22\n",
      "| epoch 4 |  iter 241 / 351 | time 5[s] | loss 1.21\n",
      "| epoch 4 |  iter 261 / 351 | time 5[s] | loss 1.21\n",
      "| epoch 4 |  iter 281 / 351 | time 5[s] | loss 1.20\n",
      "| epoch 4 |  iter 301 / 351 | time 6[s] | loss 1.17\n",
      "| epoch 4 |  iter 321 / 351 | time 6[s] | loss 1.17\n",
      "| epoch 4 |  iter 341 / 351 | time 7[s] | loss 1.16\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 168 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1180\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 633 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 153 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 403 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 853 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1027\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1483\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 888 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 283 \n",
      "---\n",
      "val acc 3.000%\n",
      "| epoch 5 |  iter 1 / 351 | time 0[s] | loss 1.14\n",
      "| epoch 5 |  iter 21 / 351 | time 0[s] | loss 1.14\n",
      "| epoch 5 |  iter 41 / 351 | time 0[s] | loss 1.14\n",
      "| epoch 5 |  iter 61 / 351 | time 1[s] | loss 1.13\n",
      "| epoch 5 |  iter 81 / 351 | time 1[s] | loss 1.11\n",
      "| epoch 5 |  iter 101 / 351 | time 1[s] | loss 1.10\n",
      "| epoch 5 |  iter 121 / 351 | time 2[s] | loss 1.09\n",
      "| epoch 5 |  iter 141 / 351 | time 2[s] | loss 1.09\n",
      "| epoch 5 |  iter 161 / 351 | time 3[s] | loss 1.08\n",
      "| epoch 5 |  iter 181 / 351 | time 3[s] | loss 1.06\n",
      "| epoch 5 |  iter 201 / 351 | time 3[s] | loss 1.05\n",
      "| epoch 5 |  iter 221 / 351 | time 4[s] | loss 1.05\n",
      "| epoch 5 |  iter 241 / 351 | time 4[s] | loss 1.04\n",
      "| epoch 5 |  iter 261 / 351 | time 5[s] | loss 1.04\n",
      "| epoch 5 |  iter 281 / 351 | time 5[s] | loss 1.03\n",
      "| epoch 5 |  iter 301 / 351 | time 5[s] | loss 1.01\n",
      "| epoch 5 |  iter 321 / 351 | time 6[s] | loss 1.01\n",
      "| epoch 5 |  iter 341 / 351 | time 6[s] | loss 1.00\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 160 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1128\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 650 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 160 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 404 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 851 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1025\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1400\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 870 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 209 \n",
      "---\n",
      "val acc 4.920%\n",
      "| epoch 6 |  iter 1 / 351 | time 0[s] | loss 1.00\n",
      "| epoch 6 |  iter 21 / 351 | time 0[s] | loss 0.98\n",
      "| epoch 6 |  iter 41 / 351 | time 1[s] | loss 0.97\n",
      "| epoch 6 |  iter 61 / 351 | time 1[s] | loss 0.97\n",
      "| epoch 6 |  iter 81 / 351 | time 2[s] | loss 0.96\n",
      "| epoch 6 |  iter 101 / 351 | time 2[s] | loss 0.95\n",
      "| epoch 6 |  iter 121 / 351 | time 3[s] | loss 0.95\n",
      "| epoch 6 |  iter 141 / 351 | time 3[s] | loss 0.95\n",
      "| epoch 6 |  iter 161 / 351 | time 4[s] | loss 0.93\n",
      "| epoch 6 |  iter 181 / 351 | time 4[s] | loss 0.92\n",
      "| epoch 6 |  iter 201 / 351 | time 5[s] | loss 0.92\n",
      "| epoch 6 |  iter 221 / 351 | time 5[s] | loss 0.92\n",
      "| epoch 6 |  iter 241 / 351 | time 6[s] | loss 0.91\n",
      "| epoch 6 |  iter 261 / 351 | time 6[s] | loss 0.90\n",
      "| epoch 6 |  iter 281 / 351 | time 7[s] | loss 0.89\n",
      "| epoch 6 |  iter 301 / 351 | time 7[s] | loss 0.89\n",
      "| epoch 6 |  iter 321 / 351 | time 7[s] | loss 0.89\n",
      "| epoch 6 |  iter 341 / 351 | time 8[s] | loss 0.88\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 165 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1117\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 661 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 160 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 848 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1027\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1400\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 860 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 233 \n",
      "---\n",
      "val acc 8.280%\n",
      "| epoch 7 |  iter 1 / 351 | time 0[s] | loss 0.87\n",
      "| epoch 7 |  iter 21 / 351 | time 0[s] | loss 0.87\n",
      "| epoch 7 |  iter 41 / 351 | time 0[s] | loss 0.87\n",
      "| epoch 7 |  iter 61 / 351 | time 1[s] | loss 0.86\n",
      "| epoch 7 |  iter 81 / 351 | time 1[s] | loss 0.86\n",
      "| epoch 7 |  iter 101 / 351 | time 1[s] | loss 0.84\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 7 |  iter 121 / 351 | time 2[s] | loss 0.84\n",
      "| epoch 7 |  iter 141 / 351 | time 2[s] | loss 0.85\n",
      "| epoch 7 |  iter 161 / 351 | time 3[s] | loss 0.83\n",
      "| epoch 7 |  iter 181 / 351 | time 3[s] | loss 0.82\n",
      "| epoch 7 |  iter 201 / 351 | time 3[s] | loss 0.82\n",
      "| epoch 7 |  iter 221 / 351 | time 4[s] | loss 0.82\n",
      "| epoch 7 |  iter 241 / 351 | time 4[s] | loss 0.81\n",
      "| epoch 7 |  iter 261 / 351 | time 5[s] | loss 0.82\n",
      "| epoch 7 |  iter 281 / 351 | time 5[s] | loss 0.81\n",
      "| epoch 7 |  iter 301 / 351 | time 5[s] | loss 0.79\n",
      "| epoch 7 |  iter 321 / 351 | time 6[s] | loss 0.79\n",
      "| epoch 7 |  iter 341 / 351 | time 6[s] | loss 0.79\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 165 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1108\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 665 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 160 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 848 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1068\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1460\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 868 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 240 \n",
      "---\n",
      "val acc 9.220%\n",
      "| epoch 8 |  iter 1 / 351 | time 0[s] | loss 0.81\n",
      "| epoch 8 |  iter 21 / 351 | time 0[s] | loss 0.77\n",
      "| epoch 8 |  iter 41 / 351 | time 0[s] | loss 0.77\n",
      "| epoch 8 |  iter 61 / 351 | time 1[s] | loss 0.78\n",
      "| epoch 8 |  iter 81 / 351 | time 1[s] | loss 0.77\n",
      "| epoch 8 |  iter 101 / 351 | time 1[s] | loss 0.76\n",
      "| epoch 8 |  iter 121 / 351 | time 2[s] | loss 0.76\n",
      "| epoch 8 |  iter 141 / 351 | time 2[s] | loss 0.75\n",
      "| epoch 8 |  iter 161 / 351 | time 3[s] | loss 0.75\n",
      "| epoch 8 |  iter 181 / 351 | time 3[s] | loss 0.75\n",
      "| epoch 8 |  iter 201 / 351 | time 3[s] | loss 0.75\n",
      "| epoch 8 |  iter 221 / 351 | time 4[s] | loss 0.74\n",
      "| epoch 8 |  iter 241 / 351 | time 4[s] | loss 0.72\n",
      "| epoch 8 |  iter 261 / 351 | time 5[s] | loss 0.72\n",
      "| epoch 8 |  iter 281 / 351 | time 5[s] | loss 0.74\n",
      "| epoch 8 |  iter 301 / 351 | time 5[s] | loss 0.74\n",
      "| epoch 8 |  iter 321 / 351 | time 6[s] | loss 0.73\n",
      "| epoch 8 |  iter 341 / 351 | time 6[s] | loss 0.71\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 164 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1137\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 665 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 160 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 849 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1037\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1437\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 869 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 231 \n",
      "---\n",
      "val acc 12.480%\n",
      "| epoch 9 |  iter 1 / 351 | time 0[s] | loss 0.70\n",
      "| epoch 9 |  iter 21 / 351 | time 0[s] | loss 0.70\n",
      "| epoch 9 |  iter 41 / 351 | time 0[s] | loss 0.70\n",
      "| epoch 9 |  iter 61 / 351 | time 1[s] | loss 0.70\n",
      "| epoch 9 |  iter 81 / 351 | time 1[s] | loss 0.70\n",
      "| epoch 9 |  iter 101 / 351 | time 1[s] | loss 0.69\n",
      "| epoch 9 |  iter 121 / 351 | time 2[s] | loss 0.69\n",
      "| epoch 9 |  iter 141 / 351 | time 2[s] | loss 0.68\n",
      "| epoch 9 |  iter 161 / 351 | time 3[s] | loss 0.68\n",
      "| epoch 9 |  iter 181 / 351 | time 3[s] | loss 0.67\n",
      "| epoch 9 |  iter 201 / 351 | time 3[s] | loss 0.68\n",
      "| epoch 9 |  iter 221 / 351 | time 4[s] | loss 0.67\n",
      "| epoch 9 |  iter 241 / 351 | time 4[s] | loss 0.67\n",
      "| epoch 9 |  iter 261 / 351 | time 5[s] | loss 0.67\n",
      "| epoch 9 |  iter 281 / 351 | time 5[s] | loss 0.66\n",
      "| epoch 9 |  iter 301 / 351 | time 5[s] | loss 0.66\n",
      "| epoch 9 |  iter 321 / 351 | time 6[s] | loss 0.66\n",
      "| epoch 9 |  iter 341 / 351 | time 6[s] | loss 0.66\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 155 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1155\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 665 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 162 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 855 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1055\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1405\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 865 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 239 \n",
      "---\n",
      "val acc 16.120%\n",
      "| epoch 10 |  iter 1 / 351 | time 0[s] | loss 0.69\n",
      "| epoch 10 |  iter 21 / 351 | time 0[s] | loss 0.64\n",
      "| epoch 10 |  iter 41 / 351 | time 1[s] | loss 0.65\n",
      "| epoch 10 |  iter 61 / 351 | time 1[s] | loss 0.64\n",
      "| epoch 10 |  iter 81 / 351 | time 2[s] | loss 0.63\n",
      "| epoch 10 |  iter 101 / 351 | time 2[s] | loss 0.63\n",
      "| epoch 10 |  iter 121 / 351 | time 3[s] | loss 0.63\n",
      "| epoch 10 |  iter 141 / 351 | time 3[s] | loss 0.63\n",
      "| epoch 10 |  iter 161 / 351 | time 4[s] | loss 0.63\n",
      "| epoch 10 |  iter 181 / 351 | time 4[s] | loss 0.64\n",
      "| epoch 10 |  iter 201 / 351 | time 5[s] | loss 0.63\n",
      "| epoch 10 |  iter 221 / 351 | time 5[s] | loss 0.65\n",
      "| epoch 10 |  iter 241 / 351 | time 6[s] | loss 0.63\n",
      "| epoch 10 |  iter 261 / 351 | time 6[s] | loss 0.63\n",
      "| epoch 10 |  iter 281 / 351 | time 6[s] | loss 0.61\n",
      "| epoch 10 |  iter 301 / 351 | time 7[s] | loss 0.61\n",
      "| epoch 10 |  iter 321 / 351 | time 7[s] | loss 0.61\n",
      "| epoch 10 |  iter 341 / 351 | time 8[s] | loss 0.61\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 164 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1140\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 668 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 161 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 856 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1047\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1428\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 865 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 235 \n",
      "---\n",
      "val acc 18.840%\n",
      "| epoch 11 |  iter 1 / 351 | time 0[s] | loss 0.57\n",
      "| epoch 11 |  iter 21 / 351 | time 0[s] | loss 0.59\n",
      "| epoch 11 |  iter 41 / 351 | time 0[s] | loss 0.58\n",
      "| epoch 11 |  iter 61 / 351 | time 1[s] | loss 0.59\n",
      "| epoch 11 |  iter 81 / 351 | time 1[s] | loss 0.59\n",
      "| epoch 11 |  iter 101 / 351 | time 1[s] | loss 0.58\n",
      "| epoch 11 |  iter 121 / 351 | time 2[s] | loss 0.58\n",
      "| epoch 11 |  iter 141 / 351 | time 2[s] | loss 0.59\n",
      "| epoch 11 |  iter 161 / 351 | time 3[s] | loss 0.58\n",
      "| epoch 11 |  iter 181 / 351 | time 3[s] | loss 0.59\n",
      "| epoch 11 |  iter 201 / 351 | time 3[s] | loss 0.59\n",
      "| epoch 11 |  iter 221 / 351 | time 4[s] | loss 0.58\n",
      "| epoch 11 |  iter 241 / 351 | time 4[s] | loss 0.58\n",
      "| epoch 11 |  iter 261 / 351 | time 5[s] | loss 0.57\n",
      "| epoch 11 |  iter 281 / 351 | time 5[s] | loss 0.57\n",
      "| epoch 11 |  iter 301 / 351 | time 5[s] | loss 0.57\n",
      "| epoch 11 |  iter 321 / 351 | time 6[s] | loss 0.57\n",
      "| epoch 11 |  iter 341 / 351 | time 6[s] | loss 0.57\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 160 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1147\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 665 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 166 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 855 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1051\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1429\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 868 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 235 \n",
      "---\n",
      "val acc 16.800%\n",
      "| epoch 12 |  iter 1 / 351 | time 0[s] | loss 0.58\n",
      "| epoch 12 |  iter 21 / 351 | time 0[s] | loss 0.55\n",
      "| epoch 12 |  iter 41 / 351 | time 0[s] | loss 0.56\n",
      "| epoch 12 |  iter 61 / 351 | time 1[s] | loss 0.58\n",
      "| epoch 12 |  iter 81 / 351 | time 1[s] | loss 0.56\n",
      "| epoch 12 |  iter 101 / 351 | time 1[s] | loss 0.55\n",
      "| epoch 12 |  iter 121 / 351 | time 2[s] | loss 0.54\n",
      "| epoch 12 |  iter 141 / 351 | time 2[s] | loss 0.54\n",
      "| epoch 12 |  iter 161 / 351 | time 3[s] | loss 0.55\n",
      "| epoch 12 |  iter 181 / 351 | time 3[s] | loss 0.55\n",
      "| epoch 12 |  iter 201 / 351 | time 3[s] | loss 0.55\n",
      "| epoch 12 |  iter 221 / 351 | time 4[s] | loss 0.54\n",
      "| epoch 12 |  iter 241 / 351 | time 4[s] | loss 0.55\n",
      "| epoch 12 |  iter 261 / 351 | time 5[s] | loss 0.55\n",
      "| epoch 12 |  iter 281 / 351 | time 5[s] | loss 0.55\n",
      "| epoch 12 |  iter 301 / 351 | time 5[s] | loss 0.53\n",
      "| epoch 12 |  iter 321 / 351 | time 6[s] | loss 0.53\n",
      "| epoch 12 |  iter 341 / 351 | time 6[s] | loss 0.54\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 161 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1147\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[92m☑\u001b[0m 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 164 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 855 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1047\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1429\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 865 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 235 \n",
      "---\n",
      "val acc 21.200%\n",
      "| epoch 13 |  iter 1 / 351 | time 0[s] | loss 0.51\n",
      "| epoch 13 |  iter 21 / 351 | time 0[s] | loss 0.53\n",
      "| epoch 13 |  iter 41 / 351 | time 0[s] | loss 0.52\n",
      "| epoch 13 |  iter 61 / 351 | time 1[s] | loss 0.52\n",
      "| epoch 13 |  iter 81 / 351 | time 1[s] | loss 0.52\n",
      "| epoch 13 |  iter 101 / 351 | time 1[s] | loss 0.51\n",
      "| epoch 13 |  iter 121 / 351 | time 2[s] | loss 0.51\n",
      "| epoch 13 |  iter 141 / 351 | time 2[s] | loss 0.51\n",
      "| epoch 13 |  iter 161 / 351 | time 3[s] | loss 0.50\n",
      "| epoch 13 |  iter 181 / 351 | time 3[s] | loss 0.51\n",
      "| epoch 13 |  iter 201 / 351 | time 3[s] | loss 0.51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 13 |  iter 221 / 351 | time 4[s] | loss 0.51\n",
      "| epoch 13 |  iter 241 / 351 | time 4[s] | loss 0.51\n",
      "| epoch 13 |  iter 261 / 351 | time 5[s] | loss 0.51\n",
      "| epoch 13 |  iter 281 / 351 | time 5[s] | loss 0.50\n",
      "| epoch 13 |  iter 301 / 351 | time 5[s] | loss 0.50\n",
      "| epoch 13 |  iter 321 / 351 | time 6[s] | loss 0.49\n",
      "| epoch 13 |  iter 341 / 351 | time 6[s] | loss 0.49\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 160 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1138\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 668 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 160 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 423 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 856 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1048\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1429\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[92m☑\u001b[0m 864 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 233 \n",
      "---\n",
      "val acc 26.140%\n",
      "| epoch 14 |  iter 1 / 351 | time 0[s] | loss 0.48\n",
      "| epoch 14 |  iter 21 / 351 | time 0[s] | loss 0.48\n",
      "| epoch 14 |  iter 41 / 351 | time 0[s] | loss 0.49\n",
      "| epoch 14 |  iter 61 / 351 | time 1[s] | loss 0.49\n",
      "| epoch 14 |  iter 81 / 351 | time 1[s] | loss 0.50\n",
      "| epoch 14 |  iter 101 / 351 | time 1[s] | loss 0.49\n",
      "| epoch 14 |  iter 121 / 351 | time 2[s] | loss 0.49\n",
      "| epoch 14 |  iter 141 / 351 | time 2[s] | loss 0.50\n",
      "| epoch 14 |  iter 161 / 351 | time 3[s] | loss 0.49\n",
      "| epoch 14 |  iter 181 / 351 | time 3[s] | loss 0.49\n",
      "| epoch 14 |  iter 201 / 351 | time 3[s] | loss 0.49\n",
      "| epoch 14 |  iter 221 / 351 | time 4[s] | loss 0.49\n",
      "| epoch 14 |  iter 241 / 351 | time 4[s] | loss 0.48\n",
      "| epoch 14 |  iter 261 / 351 | time 4[s] | loss 0.49\n",
      "| epoch 14 |  iter 281 / 351 | time 5[s] | loss 0.48\n",
      "| epoch 14 |  iter 301 / 351 | time 5[s] | loss 0.48\n",
      "| epoch 14 |  iter 321 / 351 | time 6[s] | loss 0.48\n",
      "| epoch 14 |  iter 341 / 351 | time 6[s] | loss 0.48\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 160 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1144\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 667 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 160 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 423 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 855 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[92m☑\u001b[0m 1053\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1429\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[92m☑\u001b[0m 864 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 235 \n",
      "---\n",
      "val acc 23.560%\n",
      "| epoch 15 |  iter 1 / 351 | time 0[s] | loss 0.49\n",
      "| epoch 15 |  iter 21 / 351 | time 0[s] | loss 0.47\n",
      "| epoch 15 |  iter 41 / 351 | time 0[s] | loss 0.46\n",
      "| epoch 15 |  iter 61 / 351 | time 1[s] | loss 0.48\n",
      "| epoch 15 |  iter 81 / 351 | time 1[s] | loss 0.47\n",
      "| epoch 15 |  iter 101 / 351 | time 1[s] | loss 0.47\n",
      "| epoch 15 |  iter 121 / 351 | time 2[s] | loss 0.46\n",
      "| epoch 15 |  iter 141 / 351 | time 2[s] | loss 0.46\n",
      "| epoch 15 |  iter 161 / 351 | time 3[s] | loss 0.45\n",
      "| epoch 15 |  iter 181 / 351 | time 3[s] | loss 0.45\n",
      "| epoch 15 |  iter 201 / 351 | time 3[s] | loss 0.45\n",
      "| epoch 15 |  iter 221 / 351 | time 4[s] | loss 0.45\n",
      "| epoch 15 |  iter 241 / 351 | time 4[s] | loss 0.46\n",
      "| epoch 15 |  iter 261 / 351 | time 5[s] | loss 0.47\n",
      "| epoch 15 |  iter 281 / 351 | time 5[s] | loss 0.47\n",
      "| epoch 15 |  iter 301 / 351 | time 5[s] | loss 0.46\n",
      "| epoch 15 |  iter 321 / 351 | time 6[s] | loss 0.45\n",
      "| epoch 15 |  iter 341 / 351 | time 6[s] | loss 0.46\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 163 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[92m☑\u001b[0m 1139\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 668 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 160 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 423 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 856 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1048\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1429\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 865 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 235 \n",
      "---\n",
      "val acc 27.240%\n",
      "| epoch 16 |  iter 1 / 351 | time 0[s] | loss 0.47\n",
      "| epoch 16 |  iter 21 / 351 | time 0[s] | loss 0.44\n",
      "| epoch 16 |  iter 41 / 351 | time 0[s] | loss 0.45\n",
      "| epoch 16 |  iter 61 / 351 | time 1[s] | loss 0.45\n",
      "| epoch 16 |  iter 81 / 351 | time 1[s] | loss 0.44\n",
      "| epoch 16 |  iter 101 / 351 | time 1[s] | loss 0.44\n",
      "| epoch 16 |  iter 121 / 351 | time 2[s] | loss 0.43\n",
      "| epoch 16 |  iter 141 / 351 | time 2[s] | loss 0.44\n",
      "| epoch 16 |  iter 161 / 351 | time 3[s] | loss 0.43\n",
      "| epoch 16 |  iter 181 / 351 | time 3[s] | loss 0.43\n",
      "| epoch 16 |  iter 201 / 351 | time 3[s] | loss 0.42\n",
      "| epoch 16 |  iter 221 / 351 | time 4[s] | loss 0.43\n",
      "| epoch 16 |  iter 241 / 351 | time 4[s] | loss 0.44\n",
      "| epoch 16 |  iter 261 / 351 | time 5[s] | loss 0.43\n",
      "| epoch 16 |  iter 281 / 351 | time 5[s] | loss 0.42\n",
      "| epoch 16 |  iter 301 / 351 | time 5[s] | loss 0.43\n",
      "| epoch 16 |  iter 321 / 351 | time 6[s] | loss 0.45\n",
      "| epoch 16 |  iter 341 / 351 | time 6[s] | loss 0.44\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 163 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1137\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 667 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 162 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 856 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1048\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1429\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[92m☑\u001b[0m 864 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[92m☑\u001b[0m 236 \n",
      "---\n",
      "val acc 31.180%\n",
      "| epoch 17 |  iter 1 / 351 | time 0[s] | loss 0.41\n",
      "| epoch 17 |  iter 21 / 351 | time 0[s] | loss 0.41\n",
      "| epoch 17 |  iter 41 / 351 | time 0[s] | loss 0.41\n",
      "| epoch 17 |  iter 61 / 351 | time 1[s] | loss 0.42\n",
      "| epoch 17 |  iter 81 / 351 | time 1[s] | loss 0.42\n",
      "| epoch 17 |  iter 101 / 351 | time 1[s] | loss 0.42\n",
      "| epoch 17 |  iter 121 / 351 | time 2[s] | loss 0.42\n",
      "| epoch 17 |  iter 141 / 351 | time 2[s] | loss 0.44\n",
      "| epoch 17 |  iter 161 / 351 | time 3[s] | loss 0.42\n",
      "| epoch 17 |  iter 181 / 351 | time 3[s] | loss 0.42\n",
      "| epoch 17 |  iter 201 / 351 | time 3[s] | loss 0.41\n",
      "| epoch 17 |  iter 221 / 351 | time 4[s] | loss 0.41\n",
      "| epoch 17 |  iter 241 / 351 | time 4[s] | loss 0.42\n",
      "| epoch 17 |  iter 261 / 351 | time 5[s] | loss 0.41\n",
      "| epoch 17 |  iter 281 / 351 | time 5[s] | loss 0.42\n",
      "| epoch 17 |  iter 301 / 351 | time 5[s] | loss 0.41\n",
      "| epoch 17 |  iter 321 / 351 | time 6[s] | loss 0.40\n",
      "| epoch 17 |  iter 341 / 351 | time 6[s] | loss 0.40\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 163 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1140\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 667 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 162 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 856 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1052\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1429\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[92m☑\u001b[0m 864 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[92m☑\u001b[0m 236 \n",
      "---\n",
      "val acc 36.740%\n",
      "| epoch 18 |  iter 1 / 351 | time 0[s] | loss 0.40\n",
      "| epoch 18 |  iter 21 / 351 | time 0[s] | loss 0.39\n",
      "| epoch 18 |  iter 41 / 351 | time 0[s] | loss 0.41\n",
      "| epoch 18 |  iter 61 / 351 | time 1[s] | loss 0.40\n",
      "| epoch 18 |  iter 81 / 351 | time 1[s] | loss 0.39\n",
      "| epoch 18 |  iter 101 / 351 | time 1[s] | loss 0.40\n",
      "| epoch 18 |  iter 121 / 351 | time 2[s] | loss 0.40\n",
      "| epoch 18 |  iter 141 / 351 | time 2[s] | loss 0.39\n",
      "| epoch 18 |  iter 161 / 351 | time 3[s] | loss 0.39\n",
      "| epoch 18 |  iter 181 / 351 | time 3[s] | loss 0.39\n",
      "| epoch 18 |  iter 201 / 351 | time 3[s] | loss 0.38\n",
      "| epoch 18 |  iter 221 / 351 | time 4[s] | loss 0.39\n",
      "| epoch 18 |  iter 241 / 351 | time 4[s] | loss 0.39\n",
      "| epoch 18 |  iter 261 / 351 | time 5[s] | loss 0.40\n",
      "| epoch 18 |  iter 281 / 351 | time 5[s] | loss 0.39\n",
      "| epoch 18 |  iter 301 / 351 | time 5[s] | loss 0.39\n",
      "| epoch 18 |  iter 321 / 351 | time 6[s] | loss 0.38\n",
      "| epoch 18 |  iter 341 / 351 | time 6[s] | loss 0.39\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 163 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[92m☑\u001b[0m 1139\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 668 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 164 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[92m☑\u001b[0m 857 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1051\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1429\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 865 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[92m☑\u001b[0m 236 \n",
      "---\n",
      "val acc 38.240%\n",
      "| epoch 19 |  iter 1 / 351 | time 0[s] | loss 0.36\n",
      "| epoch 19 |  iter 21 / 351 | time 0[s] | loss 0.38\n",
      "| epoch 19 |  iter 41 / 351 | time 0[s] | loss 0.36\n",
      "| epoch 19 |  iter 61 / 351 | time 1[s] | loss 0.36\n",
      "| epoch 19 |  iter 81 / 351 | time 1[s] | loss 0.38\n",
      "| epoch 19 |  iter 101 / 351 | time 1[s] | loss 0.38\n",
      "| epoch 19 |  iter 121 / 351 | time 2[s] | loss 0.37\n",
      "| epoch 19 |  iter 141 / 351 | time 2[s] | loss 0.36\n",
      "| epoch 19 |  iter 161 / 351 | time 3[s] | loss 0.37\n",
      "| epoch 19 |  iter 181 / 351 | time 3[s] | loss 0.38\n",
      "| epoch 19 |  iter 201 / 351 | time 3[s] | loss 0.36\n",
      "| epoch 19 |  iter 221 / 351 | time 4[s] | loss 0.35\n",
      "| epoch 19 |  iter 241 / 351 | time 4[s] | loss 0.36\n",
      "| epoch 19 |  iter 261 / 351 | time 4[s] | loss 0.36\n",
      "| epoch 19 |  iter 281 / 351 | time 5[s] | loss 0.37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 19 |  iter 301 / 351 | time 5[s] | loss 0.36\n",
      "| epoch 19 |  iter 321 / 351 | time 6[s] | loss 0.35\n",
      "| epoch 19 |  iter 341 / 351 | time 6[s] | loss 0.35\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 163 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1147\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 667 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 162 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[92m☑\u001b[0m 857 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[92m☑\u001b[0m 1053\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1431\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 865 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[92m☑\u001b[0m 236 \n",
      "---\n",
      "val acc 41.860%\n",
      "| epoch 20 |  iter 1 / 351 | time 0[s] | loss 0.37\n",
      "| epoch 20 |  iter 21 / 351 | time 0[s] | loss 0.35\n",
      "| epoch 20 |  iter 41 / 351 | time 0[s] | loss 0.35\n",
      "| epoch 20 |  iter 61 / 351 | time 1[s] | loss 0.34\n",
      "| epoch 20 |  iter 81 / 351 | time 1[s] | loss 0.34\n",
      "| epoch 20 |  iter 101 / 351 | time 1[s] | loss 0.34\n",
      "| epoch 20 |  iter 121 / 351 | time 2[s] | loss 0.34\n",
      "| epoch 20 |  iter 141 / 351 | time 2[s] | loss 0.34\n",
      "| epoch 20 |  iter 161 / 351 | time 3[s] | loss 0.33\n",
      "| epoch 20 |  iter 181 / 351 | time 3[s] | loss 0.32\n",
      "| epoch 20 |  iter 201 / 351 | time 3[s] | loss 0.33\n",
      "| epoch 20 |  iter 221 / 351 | time 4[s] | loss 0.34\n",
      "| epoch 20 |  iter 241 / 351 | time 4[s] | loss 0.34\n",
      "| epoch 20 |  iter 261 / 351 | time 4[s] | loss 0.34\n",
      "| epoch 20 |  iter 281 / 351 | time 5[s] | loss 0.34\n",
      "| epoch 20 |  iter 301 / 351 | time 5[s] | loss 0.33\n",
      "| epoch 20 |  iter 321 / 351 | time 6[s] | loss 0.32\n",
      "| epoch 20 |  iter 341 / 351 | time 6[s] | loss 0.32\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 163 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[92m☑\u001b[0m 1139\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 667 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 162 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[92m☑\u001b[0m 857 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1047\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1431\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 865 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 237 \n",
      "---\n",
      "val acc 47.100%\n",
      "| epoch 21 |  iter 1 / 351 | time 0[s] | loss 0.32\n",
      "| epoch 21 |  iter 21 / 351 | time 0[s] | loss 0.31\n",
      "| epoch 21 |  iter 41 / 351 | time 0[s] | loss 0.31\n",
      "| epoch 21 |  iter 61 / 351 | time 1[s] | loss 0.30\n",
      "| epoch 21 |  iter 81 / 351 | time 1[s] | loss 0.30\n",
      "| epoch 21 |  iter 101 / 351 | time 1[s] | loss 0.31\n",
      "| epoch 21 |  iter 121 / 351 | time 2[s] | loss 0.30\n",
      "| epoch 21 |  iter 141 / 351 | time 2[s] | loss 0.29\n",
      "| epoch 21 |  iter 161 / 351 | time 3[s] | loss 0.30\n",
      "| epoch 21 |  iter 181 / 351 | time 3[s] | loss 0.29\n",
      "| epoch 21 |  iter 201 / 351 | time 3[s] | loss 0.29\n",
      "| epoch 21 |  iter 221 / 351 | time 4[s] | loss 0.32\n",
      "| epoch 21 |  iter 241 / 351 | time 4[s] | loss 0.32\n",
      "| epoch 21 |  iter 261 / 351 | time 5[s] | loss 0.30\n",
      "| epoch 21 |  iter 281 / 351 | time 5[s] | loss 0.29\n",
      "| epoch 21 |  iter 301 / 351 | time 5[s] | loss 0.29\n",
      "| epoch 21 |  iter 321 / 351 | time 6[s] | loss 0.28\n",
      "| epoch 21 |  iter 341 / 351 | time 6[s] | loss 0.29\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 163 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[92m☑\u001b[0m 1139\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 667 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[92m☑\u001b[0m 163 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 423 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[92m☑\u001b[0m 857 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1054\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1430\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[92m☑\u001b[0m 864 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[92m☑\u001b[0m 236 \n",
      "---\n",
      "val acc 54.980%\n",
      "| epoch 22 |  iter 1 / 351 | time 0[s] | loss 0.27\n",
      "| epoch 22 |  iter 21 / 351 | time 0[s] | loss 0.27\n",
      "| epoch 22 |  iter 41 / 351 | time 0[s] | loss 0.26\n",
      "| epoch 22 |  iter 61 / 351 | time 1[s] | loss 0.26\n",
      "| epoch 22 |  iter 81 / 351 | time 1[s] | loss 0.26\n",
      "| epoch 22 |  iter 101 / 351 | time 1[s] | loss 0.25\n",
      "| epoch 22 |  iter 121 / 351 | time 2[s] | loss 0.25\n",
      "| epoch 22 |  iter 141 / 351 | time 2[s] | loss 0.26\n",
      "| epoch 22 |  iter 161 / 351 | time 3[s] | loss 0.27\n",
      "| epoch 22 |  iter 181 / 351 | time 3[s] | loss 0.26\n",
      "| epoch 22 |  iter 201 / 351 | time 3[s] | loss 0.25\n",
      "| epoch 22 |  iter 221 / 351 | time 4[s] | loss 0.25\n",
      "| epoch 22 |  iter 241 / 351 | time 4[s] | loss 0.26\n",
      "| epoch 22 |  iter 261 / 351 | time 4[s] | loss 0.25\n",
      "| epoch 22 |  iter 281 / 351 | time 5[s] | loss 0.24\n",
      "| epoch 22 |  iter 301 / 351 | time 5[s] | loss 0.23\n",
      "| epoch 22 |  iter 321 / 351 | time 6[s] | loss 0.23\n",
      "| epoch 22 |  iter 341 / 351 | time 6[s] | loss 0.24\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 163 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1138\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 667 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 162 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 856 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1048\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1430\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[92m☑\u001b[0m 864 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[92m☑\u001b[0m 236 \n",
      "---\n",
      "val acc 62.100%\n",
      "| epoch 23 |  iter 1 / 351 | time 0[s] | loss 0.21\n",
      "| epoch 23 |  iter 21 / 351 | time 0[s] | loss 0.23\n",
      "| epoch 23 |  iter 41 / 351 | time 0[s] | loss 0.22\n",
      "| epoch 23 |  iter 61 / 351 | time 1[s] | loss 0.22\n",
      "| epoch 23 |  iter 81 / 351 | time 1[s] | loss 0.24\n",
      "| epoch 23 |  iter 101 / 351 | time 1[s] | loss 0.22\n",
      "| epoch 23 |  iter 121 / 351 | time 2[s] | loss 0.22\n",
      "| epoch 23 |  iter 141 / 351 | time 2[s] | loss 0.21\n",
      "| epoch 23 |  iter 161 / 351 | time 3[s] | loss 0.20\n",
      "| epoch 23 |  iter 181 / 351 | time 3[s] | loss 0.21\n",
      "| epoch 23 |  iter 201 / 351 | time 3[s] | loss 0.21\n",
      "| epoch 23 |  iter 221 / 351 | time 4[s] | loss 0.21\n",
      "| epoch 23 |  iter 241 / 351 | time 4[s] | loss 0.20\n",
      "| epoch 23 |  iter 261 / 351 | time 5[s] | loss 0.21\n",
      "| epoch 23 |  iter 281 / 351 | time 5[s] | loss 0.20\n",
      "| epoch 23 |  iter 301 / 351 | time 5[s] | loss 0.20\n",
      "| epoch 23 |  iter 321 / 351 | time 6[s] | loss 0.20\n",
      "| epoch 23 |  iter 341 / 351 | time 6[s] | loss 0.19\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[92m☑\u001b[0m 1139\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 667 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[92m☑\u001b[0m 163 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 858 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1054\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1436\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[92m☑\u001b[0m 864 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[92m☑\u001b[0m 236 \n",
      "---\n",
      "val acc 70.680%\n",
      "| epoch 24 |  iter 1 / 351 | time 0[s] | loss 0.18\n",
      "| epoch 24 |  iter 21 / 351 | time 0[s] | loss 0.18\n",
      "| epoch 24 |  iter 41 / 351 | time 0[s] | loss 0.18\n",
      "| epoch 24 |  iter 61 / 351 | time 1[s] | loss 0.18\n",
      "| epoch 24 |  iter 81 / 351 | time 1[s] | loss 0.17\n",
      "| epoch 24 |  iter 101 / 351 | time 2[s] | loss 0.18\n",
      "| epoch 24 |  iter 121 / 351 | time 2[s] | loss 0.17\n",
      "| epoch 24 |  iter 141 / 351 | time 2[s] | loss 0.17\n",
      "| epoch 24 |  iter 161 / 351 | time 3[s] | loss 0.17\n",
      "| epoch 24 |  iter 181 / 351 | time 3[s] | loss 0.18\n",
      "| epoch 24 |  iter 201 / 351 | time 3[s] | loss 0.18\n",
      "| epoch 24 |  iter 221 / 351 | time 4[s] | loss 0.17\n",
      "| epoch 24 |  iter 241 / 351 | time 4[s] | loss 0.18\n",
      "| epoch 24 |  iter 261 / 351 | time 5[s] | loss 0.18\n",
      "| epoch 24 |  iter 281 / 351 | time 5[s] | loss 0.17\n",
      "| epoch 24 |  iter 301 / 351 | time 5[s] | loss 0.17\n",
      "| epoch 24 |  iter 321 / 351 | time 6[s] | loss 0.16\n",
      "| epoch 24 |  iter 341 / 351 | time 6[s] | loss 0.16\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[92m☑\u001b[0m 1139\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[92m☑\u001b[0m 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 164 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[92m☑\u001b[0m 857 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1054\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1430\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[92m☑\u001b[0m 864 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[92m☑\u001b[0m 236 \n",
      "---\n",
      "val acc 76.460%\n",
      "| epoch 25 |  iter 1 / 351 | time 0[s] | loss 0.14\n",
      "| epoch 25 |  iter 21 / 351 | time 0[s] | loss 0.15\n",
      "| epoch 25 |  iter 41 / 351 | time 0[s] | loss 0.15\n",
      "| epoch 25 |  iter 61 / 351 | time 1[s] | loss 0.14\n",
      "| epoch 25 |  iter 81 / 351 | time 1[s] | loss 0.14\n",
      "| epoch 25 |  iter 101 / 351 | time 1[s] | loss 0.14\n",
      "| epoch 25 |  iter 121 / 351 | time 2[s] | loss 0.14\n",
      "| epoch 25 |  iter 141 / 351 | time 2[s] | loss 0.14\n",
      "| epoch 25 |  iter 161 / 351 | time 3[s] | loss 0.13\n",
      "| epoch 25 |  iter 181 / 351 | time 3[s] | loss 0.14\n",
      "| epoch 25 |  iter 201 / 351 | time 3[s] | loss 0.15\n",
      "| epoch 25 |  iter 221 / 351 | time 4[s] | loss 0.14\n",
      "| epoch 25 |  iter 241 / 351 | time 4[s] | loss 0.14\n",
      "| epoch 25 |  iter 261 / 351 | time 5[s] | loss 0.14\n",
      "| epoch 25 |  iter 281 / 351 | time 5[s] | loss 0.14\n",
      "| epoch 25 |  iter 301 / 351 | time 5[s] | loss 0.13\n",
      "| epoch 25 |  iter 321 / 351 | time 6[s] | loss 0.13\n",
      "| epoch 25 |  iter 341 / 351 | time 6[s] | loss 0.12\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[92m☑\u001b[0m 1139\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[92m☑\u001b[0m 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[92m☑\u001b[0m 163 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[92m☑\u001b[0m 857 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[92m☑\u001b[0m 1053\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1430\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[92m☑\u001b[0m 864 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[92m☑\u001b[0m 236 \n",
      "---\n",
      "val acc 81.600%\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "optimizer = Adam()\n",
    "trainer = Trainer(model, optimizer)\n",
    "\n",
    "acc_list = []\n",
    "for epoch in range(max_epoch):\n",
    "    trainer.fit(x_train, t_train, max_epoch=1,\n",
    "                batch_size=batch_size, max_grad=max_grad)\n",
    "\n",
    "    correct_num = 0\n",
    "    for i in range(len(x_test)):\n",
    "        question, correct = x_test[[i]], t_test[[i]]\n",
    "        verbose = i < 10\n",
    "        correct_num += eval_seq2seq(model, question, correct,\n",
    "                                    id_to_char, verbose, is_reverse)\n",
    "\n",
    "    acc = float(correct_num) / len(x_test)\n",
    "    acc_list.append(acc)\n",
    "    print('val acc %.3f%%' % (acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl8lOX19/HPyQaBAGGJyCqgrAqKRrGKS1vrWnerWOuu2KcurY/1UVtbrW1/Wu1i+9SquFZbsdYFcaW1Kq1alCDIHoyIkAQIWwKBJCST8/tjhjEkE5gsdybJfN+vFy8z933NzLk7Tc7c13Iuc3dEREQAUhIdgIiItB9KCiIiEqWkICIiUUoKIiISpaQgIiJRSgoiIhIVWFIws8fNrMTMFjdy3szsD2ZWYGYLzezQoGIREZH4BHmn8CRw8h7OnwKMjPybCjwYYCwiIhKHwJKCu/8b2LyHJmcCT3nYHCDbzAYEFY+IiOxdWgLfexCwps7jwsixtfUbmtlUwncTdO/e/bAxY8a0SYAiIp3FvHnzNrp7zt7aJTIpWIxjMWtuuPs0YBpAbm6u5+XlBRmXiEinY2ZfxNMukbOPCoEhdR4PBooTFIuIiJDYpDATuCQyC+lIoMzdG3QdiYhI2wms+8jMpgPHA/3MrBC4A0gHcPeHgNeBU4ECYAdweVCxiIhIfAJLCu5+4V7OO3BtUO8vIiJNpxXNIiISpaQgIiJRSgoiIhKlpCAiIlFKCiIiEqWkICIiUUoKIiISpaQgIiJRSgoiIhKlpCAiIlFKCiIiEqWkICIiUUoKIiISpaQgIiJRSgoiIhKlpCAiIlFKCiIiEqWkICIiUUoKIiISpaQgIiJRSgoiIhKlpCAiIlFKCiIiEqWkICIiUUoKIiISpaQgIiJRSgoiIhKlpCAiIlFKCiIiEqWkICIiUUoKIiISlZboAEREZM9mzC/ivln5FJdWMDA7k5tPGs1ZEwcF8l5KCiIi7diM+UXc9uIiKqpDABSVVnDbi4sAAkkM6j4SEWnH7puVH00Iu1RUh7hvVn4g76ekICLSjhWXVjTpeEsFmhTM7GQzyzezAjO7Ncb5oWb2jpnNN7OFZnZqkPGIiHQk5VU1ZKTF/jM9MDszkPcMLCmYWSrwAHAKMA640MzG1Wt2O/Ccu08EpgB/CioeEZGOpGRrJRc8/F921tSSnmq7nctMT+Xmk0YH8r5BDjQfARS4+0oAM3sWOBNYWqeNAz0jP/cCigOMR0SkQygo2calj89ly46dPH754ZTtqO4Us48GAWvqPC4EJtVrcyfwDzO7HugOnBDrhcxsKjAVYOjQoa0eqIhIe/Hhyk1c/VQeGWmp/G3qVxg/uBcQzEyjWIIcU7AYx7ze4wuBJ919MHAq8LSZNYjJ3ae5e6675+bk5AQQqohI4r26sJiLH/uIfj268NL3joomhLYU5J1CITCkzuPBNOweuhI4GcDd/2tmXYF+QEmAcYmItCvuzqP/+Zxfvr6M3P1688glufTunpGQWIK8U5gLjDSz4WaWQXggeWa9NquBrwOY2VigK7AhwJhERNqVUK3zs1eW8svXl3HKQfvyl6smJSwhQIB3Cu5eY2bXAbOAVOBxd19iZncBee4+E7gJeMTMbiTctXSZu9fvYhIR6ZQqq0N8/9n5zFqynisnD+fHp44lJSVWz3vbCbTMhbu/Drxe79hP6/y8FDg6yBhERNqTunWM0lKN6pBz+2ljueqYEYkODVDtIxGRNlO/jlF1yMlINfpldUlwZF9SmQsRkTYSq47RzpAHVseoOZQURETaSFvXMWoOJQURkTbw6fptWCNjyEHVMWoOJQURkYCtWL+NCx+ZQ/eMVLrUK3AXZB2j5lBSEBEJ0PJ1W7lw2hxSzJhx3WR+de4EBmVnYsCg7EzuPmd8m5WwiIdmH4mIBGTZ2q1c9OiHpKca068+khE5Weyfk9WukkB9ulMQEQnA0uKtfPuROWSkpvDs1K8wIicr0SHFRXcKIiKtbElxGRc9+iHd0lOZPvVI9uvbPdEhxU1JQUSkFS0uCieErC5pTL/6SIb27ZbokJpE3UciIq1kUWEZ335kDlld0nh2asdLCKA7BRGRZqtbx6hfVhe2Ve6kX4+uTL/6SIb06XgJAZQURESapX4dow3lVRhwxdHDOmxCAHUfiYg0S6w6Rg489t6qhMTTWpQURESaoSPUMWoOJQURkWZorF5Re6pj1BxKCiIizXDWxIENjrW3OkbNoYFmEZEmKq+q4eUFxfTrnk56WirryioZmJ3JzSeNbtclLOKhpCAi0kS/fG0ZxaUV/P27X+Gw/fokOpxWpe4jEZEmeDe/hOkfrebqY0d0uoQASgoiInEr21HNLS8sZFT/LG48YVSiwwmEuo9EROJ05ytL2FS+k0cvOZyu6amJDicQulMQEYnDm4vX8tL8Iq772gGMH9wr0eEERklBRGQvNpZX8eOXFnPQoJ5c+9UDEh1OoNR9JCKyB+7O7S8tZltlDdPPP4T01M79XbpzX52ISAu9vKCYN5es46YTRzGqf49EhxM4JQURkUasK6vkpy8v5rD9enPVMSMSHU6bUFIQEYnB3bnlhYVUh5zffOtgUlMs0SG1CSUFEZEYnp27htkrNnDbqWMY1q/j7LHcUkoKIiL1rNm8g1+8upSjD+jLdybtl+hw2pRmH4mIRMyYX8S9s5ZTXFqJASeM7U9KknQb7aI7BRERvtxes7i0Egjvonbvm/nMmF+U2MDamJKCiAixt9esqA5x36z8BEWUGEoKIiJ03u01myrQpGBmJ5tZvpkVmNmtjbQ538yWmtkSM3smyHhERGLZWVPb6Erljr69ZlMFNtBsZqnAA8A3gEJgrpnNdPelddqMBG4Djnb3LWa2T1DxiIjE4u7cMXMJO0O1pKca1SGPnusM22s2VZB3CkcABe6+0t13As8CZ9ZrczXwgLtvAXD3kgDjERFp4C9zvmD6R6v53vH7c995BzMoOxMDBmVncvc54zv89ppNFeSU1EHAmjqPC4FJ9dqMAjCz94FU4E53f7P+C5nZVGAqwNChQwMJVkSSzwcFG7nzlaWcMHYffnjiaFJSLOmSQH1B3inEmtzr9R6nASOB44ELgUfNLLvBk9ynuXuuu+fm5OS0eqAiknxWb9rB9575mBH9uvO7Cw5JuvUIjYkrKZjZC2Z2mpk1JYkUAkPqPB4MFMdo87K7V7v750A+4SQhIhKY8qoarnpqLu7wyCW59OianuiQ2o14/8g/CHwb+NTM7jGzMXE8Zy4w0syGm1kGMAWYWa/NDOCrAGbWj3B30so4YxIRabLaWufGvy3gsw3b+dNFhyZVXaN4xJUU3P0td78IOBRYBfzTzD4ws8vNLGaKdfca4DpgFrAMeM7dl5jZXWZ2RqTZLGCTmS0F3gFudvdNLbskEZHG/e6tFfxz6Xp+ctpYjj6gX6LDaXfMvX43fyMNzfoC3wEuJtwN9FdgMjDe3Y8PKsD6cnNzPS8vr63eTkQ6kVc+Keb66fOZcvgQ7j5nPGbJM45gZvPcPXdv7eKafWRmLwJjgKeB0919beTU38xMf6FFpN1bXFTGzc9/Qu5+vbnrzIOSKiE0RbxTUv/o7m/HOhFP5hERSaQN26q4+qk8+nTL4MHvHEZGmir8NCbepDDWzD5291IAM+sNXOjufwouNBGR5psxv4j7ZuVTXFpBemoKtV7LjGsnk9OjS6JDa9fiTZdX70oIAJEVyFcHE5KISMvsKoNdVFqBAztDtZgZBSXliQ6t3Ys3KaRYnQ64SF2jjGBCEhFpmVhlsKtDnnRlsJsj3u6jWcBzZvYQ4VXJ3wUalKMQEWkPVAa7+eJNCrcA1wD/h3D5in8AjwYVlIhIS+zbqytryyobHE+2MtjNEVdScPdawquaHww2HBGRlnF3cnpkNEgKyVgGuznirX000syej2yGs3LXv6CDExFpqr/M+YKFhVs5Y8KApC+D3Rzxdh89AdwB/I5wraLLiV0FVUQkYZYUl/Hz15Zx/Ogc7p8yUZVPmyHe2UeZ7v4vwmUxvnD3O4GvBReWiEjTbK+q4fpn5tO7Wzq/+dbBSgjNFO+dQmWkbPanZnYdUARo60wRaTd+MmMxqzZt55mrj6RvlhaoNVe8dwo/ALoBNwCHES6Md2lQQYmINMXz8wp5cX4RN3x9JEeO6JvocDq0vd4pRBaqne/uNwPlhMcTRETahYKSbfxkxmKOHNGH67+mPbpaaq93Cu4eAg4zlRQUkXamsjrEdc/Mp1tGKr+fMpFUjSO0WLxjCvOBl83s78D2XQfd/cVAohIRicNdry5l+bptPHn54fTv2TXR4XQK8SaFPsAmdp9x5ICSgogkxGsL1/LMh6u55rgRHD9a815aS7wrmjWOICLtxupNO7j1hYVMHJrND0/UKuXWFO/Oa08QvjPYjbtf0eoRiYjswc6aWq6b/jFm8IcpE0lP1YY5rSne7qNX6/zcFTib8D7NIiKBq7thTvcuqZRXhXjoO4cypE+3RIfW6cTbffRC3cdmNh14K5CIRETq2LVhzq79EcqrQqSmGJXVtQmOrHNq7n3XSGBoawYiIhJLrA1zQrXaMCco8Y4pbGP3MYV1hPdYEBEJlDbMaVvxdh/1CDoQEZFY+mV1YUN5VYPj2jAnGPHup3C2mfWq8zjbzM4KLiwREXg3v4TSip0N6vRrw5zgxDumcIe7l+164O6lhPdXEBEJxIsfF3LVn/MYuU8PfnbGOG2Y00binZIaK3nE+1wRkbi5Ow//eyX3vLGco/bvy8MXH0aPrulcctTwRIeWFOL9w55nZr8FHiA84Hw9MC+wqEQkKdXWOj9/bSlPvL+K0w8eyK+/NYEuaamJDiupxNt9dD2wE/gb8BxQAVwbVFAiknyqakJc/+x8nnh/FVccPZzfX3CIEkICxDv7aDtwa8CxiEiS2lpZzTVPzeO/Kzfxo1PHcPUxI1C1/sSId/bRP80su87j3mY2K7iwRCRZlGyt5IKH5zB31Wbuv+AQph67vxJCAsU7ptAvMuMIAHffYmaqVSsizVK3llGKGakp8Phlh3PsqJxEh5b04h1TqDWzaFkLMxtGjKqpIiJ7s6uWUVFpBQ6E3DEzNm/fmejQhPiTwo+B98zsaTN7GpgN3BZcWCLSWd07a3mDWkZVNbWqZdROxDvQ/KaZ5QJTgQXAy4RnIImIxG3+6i0Ul1bGPKdaRu1DvAPNVwH/Am6K/HsauDOO551sZvlmVmBmjc5eMrPzzMwjiUdEOpmyimpun7GIcx78gJRGxpBVy6h9iLf76PvA4cAX7v5VYCKwYU9PMLNUwovdTgHGARea2bgY7XoANwAfNiFuEekA3J2ZnxRzwm9n88yHq7n0K8P4n7MPIjN99/UHqmXUfsQ7+6jS3SvNDDPr4u7LzWxvn+ARQIG7rwQws2eBM4Gl9dr9HLgX+GFTAheR9u2LTdu5fcZi/vPpRsYP6sXjlx7O+MHhuppd09Ois48GZmdy80mjVcuonYg3KRRG1inMAP5pZlvY+3acg4A1dV8DmFS3gZlNBIa4+6tm1mhSMLOphMczGDpUe/uItGc7a2qZ9u/P+P9vF5CemsKdp4/j4q8MI7VOv9FZEwcpCbRT8Q40nx358U4zewfoBby5l6fF6jmMTmM1sxTgd8Blcbz/NGAaQG5urqbCirQjddcc9M3KIMWMkm1VnDp+X376zQPZt1fXRIcoTdDkSqfuPjvOpoXAkDqPB7P73UUP4CDg3cjqxX2BmWZ2hrvnNTUuEWl79fdP3lge3vtg6jHD+dFpDYYQpQNo7h7N8ZgLjDSz4WaWAUwBZu466e5l7t7P3Ye5+zBgDqCEINIBVFaH+OCzjfxkxuIGaw4ceG3RusQEJi0W2J4I7l5jZtcBs4BU4HF3X2JmdwF57j5zz68gIm2tbldQ3QHg6lAtCwtL+aBgEx98tol5q7ews6a20dfRmoOOy9w7Vhd9bm6u5+XpZkKktdXvCgJISzFG7pPFF5t3sGNn+Pi4AT05av++HHVAX3780mLWljVcjDYoO5P3b/1am8Uue2dm89x9r2vBtHuaiABw36z8Bl1BNbXOpyXlfHvSUL4yoi+TRvSlT/eM6PlbTq5pkEi05qBjU1IQEaDxLp9QrXPXmQfFPLdrWqnWHHQeSgoigrvTrUsq26tCDc7trfyE1hx0LkHOPhKRDqC21vnRS4vZXhXabYEZqCsoGSkpiCSxmlAtN/39E6Z/tJrvHb8/vz5vAoOyMzHCg8V3nzNedwFJRt1HIkmqqibEDdPnM2vJem4+aTTXfvUAAM4+dHCCI5NEUlIQSUIVO0N89y/zmL1iAz/95jiumDw80SFJO6GkIJJkyqtquPLJuXy0ajP3nDOeKUeoyKR8SUlBJImU7ajmkic+YnFRGfdfcAhnHqLxAtmdkoJIkthYXsXFj33EZyXlPHjRoZx44L6JDknaISUFkU6sbi2j8HRT5/HLjuDYUTmJDk3aKSUFkU6qfi2jmlonIy2Fzdt3Jjgyac+0TkGkk4pVy2hnTS33zcpPUETSESgpiHRCldUhihqpZaSy1rInSgoincyCNaWc9of/NHp+b7WMJLkpKYh0ElU1Ie6btZxzH/yA7VUhrjluBJnpqbu1US0j2RsNNIt0AkuKy7jpuU9Yvm4b5x46mJ+ePo5ememM3benylpLkygpiHRg1aFaHnz3M/7wr0/J7pbBI5fk8o1x/aPnVdZamkpJQaSDWrF+Gzc99wmLiso4/eCB3HXGgfSusyuaSHMoKYh0EHUXovXomsb2qhp6dcvgTxcdyqnjByQ6POkklBREOoD6C9G2VtaQYnDjN0YqIUir0uwjkRaaMb+Io+95m+G3vsbR97zNjPlFrf4e9765vMFCtFqHh95d2ervJclNdwoiLVD/G3xRaQW3vbgIoNUGeOd9sYXissqY57QQTVqb7hREWiBWKYmK6lCrlJLYWlnN7TMWcd5DH1Bv6+QoLUST1qY7BZEWaOybelFpBevKKtm3V9cmv6a78+biddwxcwkbyqu47KhhjO7fg5+9snS3BKSFaBIEJQWRZnJ3srqmsa2yJub5yb96m29OGMCVk0cwfnCvuF6zuLSCn768hLeWrWfsgJ48ckkuBw/JBqBreqoWoknglBREmqGyOsTNzy9kW2UNqWaE3KPnMtNT+eGJoygsreC5uWuYsaCYI4b34crJwzlhbP/Ivga7C9U6T/13Fb+elU/IndtOGcMVk4eTnvplD68WoklbUFIQaaIN26qY+nQeC9aUcuspY+jfowu//seKmN/gb/zGKJ6bu4Yn3l/FNU/PY7++3bj8qGFkpqfyh7cLKC6tIKdHF7qkpbBmSwXHjsrhl2cdxJA+3RJ8lZKszOt8w+kIcnNzPS8vL9FhSJLKX7eNK56cy6btVdx/wUROPii+LS1rQrXMWrKex95bycerS2O2ufjIodx15kGYNTKqLNICZjbP3XP31k6zj0Ti9E5+Cec++AHVoVr+fs1RcScEgLTUFE6bMIAXv3c0OVldYrZ5e/kGJQRJOHUficThyfc/565XlzJm3548dlkuA3o1fyroxvKqmMe15kDaAyUFkT2oCdVy16tLeeq/X3DC2P78fsohdO/Ssl+bgdmZMXdF05oDaQ+UFETqqVt4LiMthaqaWqYeO4JbTh4Tc+ZQU9180ujdVkGD1hxI+6GkIFJH/bIVVTW1pKca4wb0bJWEAF+Wv9CaA2mPAk0KZnYy8HsgFXjU3e+pd/7/AlcBNcAG4Ap3/yLImET2JFbZiuqQc9+s/Fb9o601B9JeBTb7yMxSgQeAU4BxwIVmNq5es/lArrtPAJ4H7g0qHpG9CdV6zL5+0CCwJI8gp6QeARS4+0p33wk8C5xZt4G7v+PuOyIP5wCDA4xHpFElWyu56NE5jZ7XILAkiyC7jwYBa+o8LgQm7aH9lcAbsU6Y2VRgKsDQoUNbKz7pYOoOALdmP/wHBRu54dkFlFdVc+ERQ5gxv1iDwJK0gkwKsUblYi6fNrPvALnAcbHOu/s0YBqEVzS3VoDScQSxb0Go1vnj2wXc/68V7J+TxTNXT2JU/x5MGt5Xg8CStIJMCoXAkDqPBwPF9RuZ2QnAj4Hj3D32qh5Jeo3tW3DvrOXN+oO9sbyKHzy7gPcKNnLOxEH8/KyDousPNAgsySzIpDAXGGlmw4EiYArw7boNzGwi8DBwsruXBBiLdGAr1m/bwwBwJXe/vozTDx7IgQN7xlUmYs7KTdwwfT5lFdX86tzxnJ87ROUlRCICSwruXmNm1wGzCE9Jfdzdl5jZXUCeu88E7gOygL9HfilXu/sZQcUkHUveqs08NPsz3lpWghG777FLWgqPvfc5D/97JfvndOfMQwZxxsEDGdavO7D7OMSA7K5MHJLNG4vXMaxvd/58xRGMHdCzTa9JpL1TlVRpV2prnXfyS3jw3c/I+2ILvbulc9lRw+mXlcEvXlvWYAD47nPGc+yoHN5YvJaXFxTz0eebATh4cC+G9+vOm4vXUVlTu9t7TBySzdNXTSKrheUqRDqSeKuk6rdCEqb+t/jjR+WQ98UWVqwvZ1B2JneePo7zDx9Ct4zw/027d0lrdAD4okn7cdGk/VhbVsGrn6zl5U+KmLGgwRAWACXbKpUQRBqhOwVJiPqziXbZt2cXbjllDN+cMHC3XceaY/itr8XscjLg83tOa9Fri3Q02k9B2rX7Zi1vkBAAUlOMsycObnFCgMYXnGkhmkjjlBSkzX2+cTtFpZUxzxU3crw5bj5pNJnpqbsd00I0kT1Tx6q0maqaEA/PXskf3ylodDZRa36LVzVSkaZTUpA28eHKTfzopUV8tmE735wwgCOG9ebuN/IDLyehhWgiTaOkIIHasn0nd7+xjOfyChncO5MnLj+cr47eB4CemRn6Fi/SzigpSCDcnRc/LuKXry9ja0U13z1uf77/9ZFkZnzZx69v8SLtj5KCtIq6aw5yenShV2Yan5Zs59Ch2fzPOeMZs69WDot0BEoK0mL11xyUbKuiZFsV38odzK/OmUBKK21jKSLB05RUabHG1hx8ULBJCUGkg1FSkBZZsKZ0D2sOtIWlSEej7iNplsItO7j3zXxmflJMikFtjEUHWjks0vEoKUiTbK2s5k/vfMbj73+OAdd99QAG987kZ68s1RaWIp2AkoLEpSZUy/SPVnP/W5+yaftOzpk4iB+eNDp6N9A1PVVrDkQ6ASUFaaDu9NKB2V05ZfwA3llewmcbtjNpeB+ePG0c4wf32u05WnMg0jkoKchu6k8vLSqt5NH/fE6/rAymXXwY3xjXX1tXinRiSgpJYPdv/g27dsp2VFOwYRsFJeX8/NWlMaeXZqSmcOKB+7Zl2CKSAEoKnVzDb/4V3Pz8J/w9bw21DgUbytmwrWqvr7O2rPVKWotI+6Wk0MndG2NhWXXI+eCzTRw8JJvjRuVwwD5ZjNwniwP2yeLCR+bE3NNA00tFkoOSQic2d9XmPW5aM+Paoxsc+38njWmwTaaml4okDyWFTqiotIJ73ljOK81YWKaNaUSSm5JCJ7JjZw0PzV7JtH9/hjvc8PWRDM7uyh0zm7awTNNLRZKXkkIn4O7M/KSYe95YztqySr45YQC3njKGwb27AZCRpoVlIhIfJYUOpv700gsOH8zsFRuZ98UWDhrUk99PmcgRw/vs9hx98xeReCkpdCCxppf+9p+fktUllXvPncC5hw0mVaWqRaQFlBQ6kMb2LejRNZ3zDx+SgIhEpLNRUmjn3J1FRWW8vmhdo/sWrNPCMhFpJUoKCdRY+Ql3Z8GaUt5YvI7XF62lcEsFaSlGl7QUqmpqG7yOFpaJSGtRUkiQWOMDt7ywkJfmF/Lp+nKKyypJTzUmH9CPG74+khPH9efd/A1aWCYigVJSSJD7ZuU3GB+oqqll9oqNnDB2H246cTQnjOtPr8z06HktLBORoCkptCF3J3/9Nv6zYiNFjexfbMCjlx7e6GtoeqmIBElJoRXFGiOYPLIf7xdsZPaKDbz36UZKIhVJ01KMmhj1JzQ+ICKJpKTQSmKNEdz43AI88ne/d7d0Jo/M4ZiR/ThmZD8+XLlZ4wMi0u4kRVLY2yYzzX1OqNYpKClnUVEZd7y8uMEYgTv07JrGX66axIEDe+22sEzjAyLSHgWaFMzsZOD3QCrwqLvfU+98F+Ap4DBgE3CBu69qzRhifYO/7cVFAI3+AY79nIWs31pBTo+uLCoqY1FhGUuKt8ZcTFbXtsoaJgzOjnlO4wMi0t4ElhTMLBV4APgGUAjMNbOZ7r60TrMrgS3ufoCZTQF+BVzQmnHEmuVTUR3iZ68soTpUixMeAK51qHXHvbHn1HL3G/lAuJvnoEE9mXLEECYM7sX4Qdlc8viH2pxGRDq8IO8UjgAK3H0lgJk9C5wJ1E0KZwJ3Rn5+HvijmZm7x9gBoHmKG5nls2VHNTc/v7DJr/ePG49l/5ysBjWGtDmNiHQGQSaFQcCaOo8LgUmNtXH3GjMrA/oCG+s2MrOpwNTIw3Izy483iPScYeMtNS2j/nEP1eys3rBqUVOfM/pXsZ8DkJLZs09qVp9BlpqW4aGanaHyzUVn/2Lr5nhjbQP9qPe/bRJJ5muH5L5+XXvYfvE8IcikEKtcZ/07gHja4O7TgGktDsgsz91zW/o6HVUyX38yXzsk9/Xr2pt27SlBBUP4zqBu6c7BQHFjbcwsDegFtKdv1iIiSSXIpDAXGGlmw80sA5gCzKzXZiZwaeTn84C3W3M8QUREmiaw7qPIGMF1wCzCU1Ifd/clZnYXkOfuM4HHgKfNrIDwHcKUoOKJaHEXVAeXzNefzNcOyX39uvYmMH0xFxGRXYLsPhIRkQ5GSUFERKKSJimY2clmlm9mBWZ2a6LjaUtmtsrMFpnZAjPLS3Q8QTOzx82sxMwW1znWx8z+aWafRv7bO5ExBqWRa7/TzIoin/8CMzs1kTEGxcyGmNk7ZrbMzJaY2fcjx5Pls2/s+pv0+SfFmEKk5MYK6pTcAC6sV3Kj0zKzVUCuuyfFAh4zOxYoB55y94Mix+4FNrv7PZEvBb3d/ZZExhmERq79TqDc3X+dyNiCZmYDgAHu/rGZ9QDmAWe6eJD/AAADxUlEQVQBl5Ecn31j138+Tfj8k+VOIVpyw913ArtKbkgn5O7/puF6lzOBP0d+/jPhX5ZOp5FrTwruvtbdP478vA1YRrhqQrJ89o1df5MkS1KIVXIjmcqTOvAPM5sXKRmSjPq7+1oI//IA+yQ4nrZ2nZktjHQvdcruk7rMbBgwEfiQJPzs610/NOHzT5akEFc5jU7saHc/FDgFuDbSxSDJ40Fgf+AQYC3wm8SGEywzywJeAH7g7lsTHU9bi3H9Tfr8kyUpxFNyo9Ny9+LIf0uAlwh3pyWb9ZE+1119ryUJjqfNuPt6dw+5ey3wCJ348zezdMJ/EP/q7i9GDifNZx/r+pv6+SdLUoin5EanZGbdI4NOmFl34ERg8Z6f1SnVLalyKfByAmNpU7v+IEacTSf9/M3MCFdJWObuv61zKik++8auv6mff1LMPgKITMO6ny9LbvwywSG1CTMbQfjuAMJlTZ7p7NduZtOB4wmXDV4P3AHMAJ4DhgKrgW+5e6cbkG3k2o8n3HXgwCrgml197J2JmU0G/gMsAmojh39EuF89GT77xq7/Qprw+SdNUhARkb1Llu4jERGJg5KCiIhEKSmIiEiUkoKIiEQpKYiISJSSgkjAzOx4M3s10XGIxENJQUREopQURCLM7Dtm9lGk5vzDZpZqZuVm9hsz+9jM/mVmOZG2h5jZnEiRsZd2FRkzswPM7C0z+yTynP0jL59lZs+b2XIz+2tk9Slmdo+ZLY28TqcubS0dg5KCCGBmY4ELCBcPPAQIARcB3YGPIwUFZxNeIQzwFHCLu08gvIJ01/G/Ag+4+8HAUYQLkEG4YuUPgHHACOBoM+tDuOzAgZHX+UWwVymyd0oKImFfBw4D5prZgsjjEYTLBfwt0uYvwGQz6wVku/vsyPE/A8dGakwNcveXANy90t13RNp85O6FkaJkC4BhwFagEnjUzM4BdrUVSRglBZEwA/7s7odE/o129ztjtNtTXZhYJdp3qarzcwhIc/cawhUrXyC88cubTYxZpNUpKYiE/Qs4z8z2gei+vvsR/h05L9Lm28B77l4GbDGzYyLHLwZmR2rXF5rZWZHX6GJm3Rp7w0jd+17u/jrhrqVDgrgwkaZIS3QAIu2Buy81s9sJ71CXAlQD1wLbgQPNbB5QRnjcAcIlmB+K/NFfCVweOX4x8LCZ3RV5jW/t4W17AC+bWVfCdxk3tvJliTSZqqSK7IGZlbt7VqLjEGkr6j4SEZEo3SmIiEiU7hRERCRKSUFERKKUFEREJEpJQUREopQUREQk6n8BcPmTkIWhwYEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a23450f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# グラフの描画\n",
    "x = np.arange(len(acc_list))\n",
    "plt.plot(x, acc_list, marker='o')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.ylim(0, 1.0)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
