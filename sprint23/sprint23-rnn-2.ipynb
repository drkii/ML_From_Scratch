{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/szkhome/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "import re\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from pandas import read_csv\n",
    "import collections\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import log_loss,confusion_matrix,classification_report, accuracy_score\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from common.time_layers import *\n",
    "from common.np import *  \n",
    "from common.base_model import BaseModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題：Backpropagationで勾配爆発、勾配消失が起こる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実験１：勾配爆発"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 2 #Minibatch\n",
    "H = 3 #Hidden状態ベクトルの次元数\n",
    "T = 20 #時系列データの長さ\n",
    "\n",
    "dh=np.ones((N, H)) #dhをnp.onesで初期化する\n",
    "np.random.seed(3)\n",
    "Wh=np.random.randn(H,H)\n",
    "\n",
    "norm_list = []\n",
    "for t in range(T):\n",
    "    dh = np.dot(dh, Wh.T)\n",
    "    norm = np.sqrt(np.sum(dh**2))/N #L2ノルムを求める（各要素の２条の総和に対してSQRTを適用）\n",
    "    norm_list.append(norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.4684068094579303, 3.3357049741610365, 4.783279375373182, 6.279587332087612, 8.080776465019053, 10.251163032292936, 12.936063506609896, 16.276861327786712, 20.45482961834598, 25.688972842084684, 32.25315718048336, 40.48895641683869, 50.8244073070191, 63.79612654485427, 80.07737014308985, 100.5129892205125, 126.16331847536823, 158.35920648258823, 198.7710796761195, 249.495615421267]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1bfd7208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(norm_list)\n",
    "\n",
    "# グラフの描画\n",
    "plt.plot(np.arange(len(norm_list)), norm_list)\n",
    "plt.xticks([0, 4, 9, 14, 19], [1, 5, 10, 15, 20])\n",
    "plt.xlabel('time step')\n",
    "plt.ylabel('norm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "勾配の大きさが、時間とともに、指数的に増加していることがわかります。勾配爆発が見られました。勾配爆発がおこると、オーバーフローを起こして最後はNaNのような値が発生することになります。そのためNNは正しい学習を行えなくなります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実験２：勾配消失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 2 #Minibatch\n",
    "H = 3 #Hidden状態ベクトルの次元数\n",
    "T = 20 #時系列データの長さ\n",
    "\n",
    "dh=np.ones((N, H)) #dhをnp.onesで初期化する\n",
    "np.random.seed(3)\n",
    "#Wh=np.random.randn(H,H) #before\n",
    "Wh=np.random.randn(H,H)*0.5 #after\n",
    "\n",
    "norm_list = []\n",
    "for t in range(T):\n",
    "    dh = np.dot(dh, Wh.T)\n",
    "    norm = np.sqrt(np.sum(dh**2))/N #L2ノルムを求める（各要素の２条の総和に対してSQRTを適用）\n",
    "    norm_list.append(norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.2342034047289652, 0.8339262435402591, 0.5979099219216477, 0.39247420825547574, 0.2525242645318454, 0.16017442237957713, 0.10106299614538981, 0.06358148956166684, 0.03995083909833199, 0.025086887541098325, 0.015748611904532892, 0.009884999125204758, 0.006204151282595105, 0.003893806551809953, 0.002443767399386287, 0.0015337065005571365, 0.0009625497320203265, 0.0006040924319556741, 0.00037912574706291106, 0.00023793756048323344]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1c308898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(norm_list)\n",
    "\n",
    "# グラフの描画\n",
    "plt.plot(np.arange(len(norm_list)), norm_list)\n",
    "plt.xticks([0, 4, 9, 14, 19], [1, 5, 10, 15, 20])\n",
    "plt.xlabel('time step')\n",
    "plt.ylabel('norm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "勾配消失しました。初期値で半分にした値（Wh）をT回繰り返し乗算しているから、指数的な変化が起こっていることがわかります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 対策"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 勾配爆発への対策: Clipping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定番の方法：Clippingを行います。LSTMでは定番の方法とのことです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dW1 = np.random.rand(3, 3) * 10\n",
    "dW2 = np.random.rand(3, 3) * 10\n",
    "grads = [dW1, dW2]\n",
    "max_norm = 5.0\n",
    "\n",
    "def clip_grads(grads, max_norm):\n",
    "    total_norm=0\n",
    "    for grad in grads:\n",
    "        total_norm += np.sum(grad ** 2)\n",
    "        \n",
    "    total_norm =np.sqrt(total_norm)\n",
    "    \n",
    "    rate=max_norm / (total_norm + 1e-6)\n",
    "    if rate < 1:\n",
    "        for grad in grads:\n",
    "            grad *= rate\n",
    "            \n",
    "clip_grads(grads, max_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 勾配消失への対策: ゲート付きRNN（ここではLSTM）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNNでの学習では、勾配消失も大きな問題になります。勾配消失に関しては、先ほども見たように、T回の乗算をしていくことになっているので、簡単に起こってしまいます。\n",
    "そのため、勾配消失問題を解決しようと思うと、RNNのアーキテクチャーを変更するということが手段の一つになります。ここではアーキテクチャーを変える「ゲート付きRNN」がひとつ解になります。というのも、ゲート付きは、cという専用の記憶部が存在するからです。ここでは、ゲート付きRNNのひとつであるLSTMを実装し、これを対策とします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "結論から言うと、なぜLSTMでは勾配消失がおきないかというと、記憶せるCを作り、ここの逆伝播に、単純に＋と×しかないからです。\n",
    "\n",
    "またその×部分も、行列の積ではなく、要素ごとのアダマール積であるため起こしにくい理由があります。しかもその×ノードの計算は、forgetゲートによってコントロールされており、ここでforgetゲートが忘れるべきと判断したものは、その勾配の要素は小さくなりますが、忘れないと導いた要素は。その勾配のう要素を劣化させることなく過去方向へ伝えら得ることになります。以上のことから、勾配消失がおきにくいことが期待できることになります。特に長期に渡って覚えておくべき情報に関しては、記憶セルが保持していることになります。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4つのアフィン変換の方)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM:\n",
    "\n",
    "    def __init__(self, Wx, Wh, b):\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.cache = None\n",
    "\n",
    "    def forward(self, x, h_prev, c_prev):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, H = h_prev.shape\n",
    "\n",
    "        A = np.dot(x, Wx) + np.dot(h_prev, Wh) + b\n",
    "\n",
    "        f = A[:, :H]\n",
    "        g = A[:, H:2*H]\n",
    "        i = A[:, 2*H:3*H]\n",
    "        o = A[:, 3*H:]\n",
    "\n",
    "        f = sigmoid(f)\n",
    "        g = np.tanh(g)\n",
    "        i = sigmoid(i)\n",
    "        o = sigmoid(o)\n",
    "\n",
    "        c_next = f * c_prev + g * i\n",
    "        h_next = o * np.tanh(c_next)\n",
    "\n",
    "        self.cache = (x, h_prev, c_prev, i, f, g, o, c_next)\n",
    "        return h_next, c_next\n",
    "\n",
    "    def backward(self, dh_next, dc_next):\n",
    "        Wx, Wh, b = self.params\n",
    "        x, h_prev, c_prev, i, f, g, o, c_next = self.cache\n",
    "\n",
    "        tanh_c_next = np.tanh(c_next)\n",
    "\n",
    "        ds = dc_next + (dh_next * o) * (1 - tanh_c_next ** 2)\n",
    "\n",
    "        dc_prev = ds * f\n",
    "\n",
    "        di = ds * g\n",
    "        df = ds * c_prev\n",
    "        do = dh_next * tanh_c_next\n",
    "        dg = ds * i\n",
    "\n",
    "        di *= i * (1 - i)\n",
    "        df *= f * (1 - f)\n",
    "        do *= o * (1 - o)\n",
    "        dg *= (1 - g ** 2)\n",
    "\n",
    "        dA = np.hstack((df, dg, di, do))\n",
    "\n",
    "        dWh = np.dot(h_prev.T, dA)\n",
    "        dWx = np.dot(x.T, dA)\n",
    "        db = dA.sum(axis=0)\n",
    "\n",
    "        self.grads[0][...] = dWx\n",
    "        self.grads[1][...] = dWh\n",
    "        self.grads[2][...] = db\n",
    "\n",
    "        dx = np.dot(dA, Wx.T)\n",
    "        dh_prev = np.dot(dA, Wh.T)\n",
    "\n",
    "        return dx, dh_prev, dc_prev\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTMをTの時間個分回せるようにする（Time RNNとほぼ同じ）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeLSTM:\n",
    "    def __init__(self, Wx, Wh, b, stateful=False):\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.layers = None\n",
    "\n",
    "        self.h, self.c = None, None\n",
    "        self.dh = None\n",
    "        self.stateful = stateful\n",
    "\n",
    "    def forward(self, xs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, D = xs.shape\n",
    "        H = Wh.shape[0]\n",
    "\n",
    "        self.layers = []\n",
    "        hs = np.empty((N, T, H), dtype='f')\n",
    "\n",
    "        if not self.stateful or self.h is None:\n",
    "            self.h = np.zeros((N, H), dtype='f')\n",
    "        if not self.stateful or self.c is None:\n",
    "            self.c = np.zeros((N, H), dtype='f')\n",
    "\n",
    "        for t in range(T):\n",
    "            layer = LSTM(*self.params)\n",
    "            self.h, self.c = layer.forward(xs[:, t, :], self.h, self.c)\n",
    "            hs[:, t, :] = self.h\n",
    "\n",
    "            self.layers.append(layer)\n",
    "\n",
    "        return hs\n",
    "\n",
    "    def backward(self, dhs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, H = dhs.shape\n",
    "        D = Wx.shape[0]\n",
    "\n",
    "        dxs = np.empty((N, T, D), dtype='f')\n",
    "        dh, dc = 0, 0\n",
    "\n",
    "        grads = [0, 0, 0]\n",
    "        for t in reversed(range(T)):\n",
    "            layer = self.layers[t]\n",
    "            dx, dh, dc = layer.backward(dhs[:, t, :] + dh, dc)\n",
    "            dxs[:, t, :] = dx\n",
    "            for i, grad in enumerate(layer.grads):\n",
    "                grads[i] += grad\n",
    "\n",
    "        for i, grad in enumerate(grads):\n",
    "            self.grads[i][...] = grad\n",
    "        self.dh = dh\n",
    "        return dxs\n",
    "\n",
    "    def set_state(self, h, c=None):\n",
    "        self.h, self.c = h, c\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.h, self.c = None, None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ゲートはデータの流れをコントロールします。ゲートの開き具合は、０−１までの実数で表されます。その数値によって、次へ流す水の量をコントロールするのです。ちなみにゲートの開き具合はSigmoid関数で表します。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一方、実質的な「情報」を持つデータにはtanj関数が活性化関数として用いられる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下記には、上記の層を追加したものを実装します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM二重化したものの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTMレイヤを2層利用し、各層にDropoutを使う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BetterRnnlm(BaseModel):\n",
    "\n",
    "    def __init__(self, vocab_size=10000, wordvec_size=650, hidden_size=650, dropout_ratio=0.5):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        embed_W = (rn(V, D) / 100)\n",
    "        lstm_Wx1 = (rn(D, 4 * H) / np.sqrt(D))\n",
    "        lstm_Wh1 = (rn(H, 4 * H) / np.sqrt(H))\n",
    "        lstm_b1 = np.zeros(4 * H)\n",
    "        lstm_Wx2 = (rn(H, 4 * H) / np.sqrt(H))\n",
    "        lstm_Wh2 = (rn(H, 4 * H) / np.sqrt(H))\n",
    "        lstm_b2 = np.zeros(4 * H).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "\n",
    "        self.layers = [\n",
    "            TimeEmbedding(embed_W),\n",
    "            TimeDropout(dropout_ratio),\n",
    "            TimeLSTM(lstm_Wx1, lstm_Wh1, lstm_b1, stateful=True),\n",
    "            TimeDropout(dropout_ratio),\n",
    "            TimeLSTM(lstm_Wx2, lstm_Wh2, lstm_b2, stateful=True),\n",
    "            TimeDropout(dropout_ratio),\n",
    "            TimeAffine(embed_W.T, affine_b)  \n",
    "        ]\n",
    "        self.loss_layer = TimeSoftmaxWithLoss()\n",
    "        self.lstm_layers = [self.layers[2], self.layers[4]]\n",
    "        self.drop_layers = [self.layers[1], self.layers[3], self.layers[5]]\n",
    "\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "    def predict(self, xs, train_flg=False):\n",
    "        for layer in self.drop_layers:\n",
    "            layer.train_flg = train_flg\n",
    "\n",
    "        for layer in self.layers:\n",
    "            xs = layer.forward(xs)\n",
    "        return xs\n",
    "\n",
    "    def forward(self, xs, ts, train_flg=True):\n",
    "        score = self.predict(xs, train_flg)\n",
    "        loss = self.loss_layer.forward(score, ts)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n",
    "\n",
    "    def reset_state(self):\n",
    "        for layer in self.lstm_layers:\n",
    "            layer.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習する(副読本通り）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # coding: utf-8\n",
    "# import sys\n",
    "# sys.path.append('..')\n",
    "# from common import config\n",
    "# # GPUで実行する場合は下記のコメントアウトを消去（要cupy）\n",
    "# # ==============================================\n",
    "# # config.GPU = True\n",
    "# # ==============================================\n",
    "# from common.optimizer import SGD\n",
    "# from common.trainer import RnnlmTrainer\n",
    "# from common.util import eval_perplexity, to_gpu\n",
    "# from dataset import ptb\n",
    "# from better_rnnlm import BetterRnnlm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ハイパーパラメータの設定\n",
    "# batch_size = 20\n",
    "# wordvec_size = 650\n",
    "# hidden_size = 650\n",
    "# time_size = 35\n",
    "# lr = 20.0\n",
    "# max_epoch = 1\n",
    "# max_grad = 0.25\n",
    "# dropout = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 学習データの読み込み\n",
    "# corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "# corpus_val, _, _ = ptb.load_data('val')\n",
    "# corpus_test, _, _ = ptb.load_data('test')\n",
    "\n",
    "# if config.GPU:\n",
    "#     corpus = to_gpu(corpus)\n",
    "#     corpus_val = to_gpu(corpus_val)\n",
    "#     corpus_test = to_gpu(corpus_test)\n",
    "\n",
    "# vocab_size = len(word_to_id)\n",
    "# xs = corpus[:-1]\n",
    "# ts = corpus[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model = BetterRnnlm(vocab_size, wordvec_size, hidden_size, dropout)\n",
    "# optimizer = SGD(lr)\n",
    "# trainer = RnnlmTrainer(model, optimizer)\n",
    "\n",
    "# best_ppl = float('inf')\n",
    "# for epoch in range(max_epoch):\n",
    "#     trainer.fit(xs, ts, max_epoch=1, batch_size=batch_size,\n",
    "#                 time_size=time_size, max_grad=max_grad)\n",
    "\n",
    "#     model.reset_state()\n",
    "#     ppl = eval_perplexity(model, corpus_val)\n",
    "#     print('valid perplexity: ', ppl)\n",
    "\n",
    "#     if best_ppl > ppl:\n",
    "#         best_ppl = ppl\n",
    "#         model.save_params()\n",
    "#     else:\n",
    "#         lr /= 4.0\n",
    "#         optimizer.lr = lr\n",
    "\n",
    "#     model.reset_state()\n",
    "#     print('-' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # テストデータでの評価\n",
    "# model.reset_state()\n",
    "# ppl_test = eval_perplexity(model, corpus_test)\n",
    "# print('test perplexity: ', ppl_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Womens Clothing Reviewでやる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/szkhome/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = read_csv('./Womens Clothing E-Commerce Reviews.csv')\n",
    "reviews = dataset['Review Text'].astype('str')\n",
    "#recommend = dataset['Recommended IND']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>Department Name</th>\n",
       "      <th>Class Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>767</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Initmates</td>\n",
       "      <td>Intimate</td>\n",
       "      <td>Intimates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1080</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1077</td>\n",
       "      <td>60</td>\n",
       "      <td>Some major design flaws</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1049</td>\n",
       "      <td>50</td>\n",
       "      <td>My favorite buy!</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>847</td>\n",
       "      <td>47</td>\n",
       "      <td>Flattering shirt</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Blouses</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Clothing ID  Age                    Title  \\\n",
       "0           0          767   33                      NaN   \n",
       "1           1         1080   34                      NaN   \n",
       "2           2         1077   60  Some major design flaws   \n",
       "3           3         1049   50         My favorite buy!   \n",
       "4           4          847   47         Flattering shirt   \n",
       "\n",
       "                                         Review Text  Rating  Recommended IND  \\\n",
       "0  Absolutely wonderful - silky and sexy and comf...       4                1   \n",
       "1  Love this dress!  it's sooo pretty.  i happene...       5                1   \n",
       "2  I had such high hopes for this dress and reall...       3                0   \n",
       "3  I love, love, love this jumpsuit. it's fun, fl...       5                1   \n",
       "4  This shirt is very flattering to all due to th...       5                1   \n",
       "\n",
       "   Positive Feedback Count   Division Name Department Name Class Name  \n",
       "0                        0       Initmates        Intimate  Intimates  \n",
       "1                        4         General         Dresses    Dresses  \n",
       "2                        0         General         Dresses    Dresses  \n",
       "3                        0  General Petite         Bottoms      Pants  \n",
       "4                        6         General            Tops    Blouses  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Absolutely wonderful - silky and sexy and comf...\n",
       "1    Love this dress!  it's sooo pretty.  i happene...\n",
       "2    I had such high hopes for this dress and reall...\n",
       "3    I love, love, love this jumpsuit. it's fun, fl...\n",
       "4    This shirt is very flattering to all due to th...\n",
       "Name: Review Text, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データセットをtextという変数に入れる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I love tracy reese dresses, but this one is no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I aded this in my basket at hte last mintue to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I ordered this in carbon for store pick up, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I love this dress. i usually get an xs but it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I'm 5\"5' and 125 lbs. i ordered the s petite t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Dress runs small esp where the zipper area run...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>This dress is perfection! so pretty and flatte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>More and more i find myself reliant on the rev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Bought the black xs to go under the larkspur m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>This is a nice choice for holiday gatherings. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>I took these out of the package and wanted the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Material and color is nice.  the leg opening i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Took a chance on this blouse and so glad i did...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>A flattering, super cozy coat.  will work well...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>I love the look and feel of this tulle dress. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>If this product was in petite, i would get the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>I'm upset because for the price of the dress, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>First of all, this is not pullover styling. th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Cute little dress fits tts. it is a little hig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>I love this shirt because when i first saw it,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Loved the material, but i didnt really look at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>I have been waiting for this sweater coat to s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>The colors weren't what i expected either. the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>I have several of goodhyouman shirts and i get...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>This sweater is so comfy and classic - it bala...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23456</th>\n",
       "      <td>I have been on a search for a dress with sleev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23457</th>\n",
       "      <td>These pants are soft, fun print and comfy. the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23458</th>\n",
       "      <td>This is my new favorite sweater. it is lightwe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23459</th>\n",
       "      <td>This is my new favorite dress! my only complai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23460</th>\n",
       "      <td>I purchased this for a very good price and i t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23461</th>\n",
       "      <td>I tried these on at the store and the fit was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23462</th>\n",
       "      <td>The pattern of this skirt is adorable and look...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23463</th>\n",
       "      <td>These pants overall are very comfortable, but ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23464</th>\n",
       "      <td>I wore this dress to work the other day and go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23465</th>\n",
       "      <td>I bought this dress for work and post work hap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23466</th>\n",
       "      <td>This dress has a great design and fits very we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23467</th>\n",
       "      <td>I worry when i have an elastic waist, or somet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23468</th>\n",
       "      <td>I love this little chemise! the adjustable str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23469</th>\n",
       "      <td>My size was not available so based on reviews ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23470</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23471</th>\n",
       "      <td>Love the way these pants look in the pictures,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23472</th>\n",
       "      <td>I saw the shirt on the retailer website and ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23473</th>\n",
       "      <td>Great quality and extremely flattering. bonus ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23474</th>\n",
       "      <td>Yes, this is a great dress! i wasn't sure abou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23475</th>\n",
       "      <td>Cute dress but not for me.  the waist is too h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23476</th>\n",
       "      <td>These bottoms are very cute but defiantly chee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23477</th>\n",
       "      <td>I'm so impressed with the beautiful color comb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23478</th>\n",
       "      <td>I was surprised at the positive reviews for th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23479</th>\n",
       "      <td>So i wasn't sure about ordering this skirt bec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23480</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23481</th>\n",
       "      <td>I was very happy to snag this dress at such a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23482</th>\n",
       "      <td>It reminds me of maternity clothes. soft, stre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23483</th>\n",
       "      <td>This fit well, but the top was very see throug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23484</th>\n",
       "      <td>I bought this dress for a wedding i have this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23485</th>\n",
       "      <td>This dress in a lovely platinum is feminine an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23486 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Review Text\n",
       "0      Absolutely wonderful - silky and sexy and comf...\n",
       "1      Love this dress!  it's sooo pretty.  i happene...\n",
       "2      I had such high hopes for this dress and reall...\n",
       "3      I love, love, love this jumpsuit. it's fun, fl...\n",
       "4      This shirt is very flattering to all due to th...\n",
       "5      I love tracy reese dresses, but this one is no...\n",
       "6      I aded this in my basket at hte last mintue to...\n",
       "7      I ordered this in carbon for store pick up, an...\n",
       "8      I love this dress. i usually get an xs but it ...\n",
       "9      I'm 5\"5' and 125 lbs. i ordered the s petite t...\n",
       "10     Dress runs small esp where the zipper area run...\n",
       "11     This dress is perfection! so pretty and flatte...\n",
       "12     More and more i find myself reliant on the rev...\n",
       "13     Bought the black xs to go under the larkspur m...\n",
       "14     This is a nice choice for holiday gatherings. ...\n",
       "15     I took these out of the package and wanted the...\n",
       "16     Material and color is nice.  the leg opening i...\n",
       "17     Took a chance on this blouse and so glad i did...\n",
       "18     A flattering, super cozy coat.  will work well...\n",
       "19     I love the look and feel of this tulle dress. ...\n",
       "20     If this product was in petite, i would get the...\n",
       "21     I'm upset because for the price of the dress, ...\n",
       "22     First of all, this is not pullover styling. th...\n",
       "23     Cute little dress fits tts. it is a little hig...\n",
       "24     I love this shirt because when i first saw it,...\n",
       "25     Loved the material, but i didnt really look at...\n",
       "26     I have been waiting for this sweater coat to s...\n",
       "27     The colors weren't what i expected either. the...\n",
       "28     I have several of goodhyouman shirts and i get...\n",
       "29     This sweater is so comfy and classic - it bala...\n",
       "...                                                  ...\n",
       "23456  I have been on a search for a dress with sleev...\n",
       "23457  These pants are soft, fun print and comfy. the...\n",
       "23458  This is my new favorite sweater. it is lightwe...\n",
       "23459  This is my new favorite dress! my only complai...\n",
       "23460  I purchased this for a very good price and i t...\n",
       "23461  I tried these on at the store and the fit was ...\n",
       "23462  The pattern of this skirt is adorable and look...\n",
       "23463  These pants overall are very comfortable, but ...\n",
       "23464  I wore this dress to work the other day and go...\n",
       "23465  I bought this dress for work and post work hap...\n",
       "23466  This dress has a great design and fits very we...\n",
       "23467  I worry when i have an elastic waist, or somet...\n",
       "23468  I love this little chemise! the adjustable str...\n",
       "23469  My size was not available so based on reviews ...\n",
       "23470                                                NaN\n",
       "23471  Love the way these pants look in the pictures,...\n",
       "23472  I saw the shirt on the retailer website and ne...\n",
       "23473  Great quality and extremely flattering. bonus ...\n",
       "23474  Yes, this is a great dress! i wasn't sure abou...\n",
       "23475  Cute dress but not for me.  the waist is too h...\n",
       "23476  These bottoms are very cute but defiantly chee...\n",
       "23477  I'm so impressed with the beautiful color comb...\n",
       "23478  I was surprised at the positive reviews for th...\n",
       "23479  So i wasn't sure about ordering this skirt bec...\n",
       "23480                                                NaN\n",
       "23481  I was very happy to snag this dress at such a ...\n",
       "23482  It reminds me of maternity clothes. soft, stre...\n",
       "23483  This fit well, but the top was very see throug...\n",
       "23484  I bought this dress for a wedding i have this ...\n",
       "23485  This dress in a lovely platinum is feminine an...\n",
       "\n",
       "[23486 rows x 1 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = dataset[['Review Text']]\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 欠損を処理する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/szkhome/.pyenv/versions/anaconda3-4.3.0/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/szkhome/.pyenv/versions/anaconda3-4.3.0/lib/python3.6/site-packages/pandas/core/frame.py:2434: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.ix._setitem_with_indexer(indexer, value)\n",
      "/Users/szkhome/.pyenv/versions/anaconda3-4.3.0/lib/python3.6/site-packages/pandas/core/frame.py:2414: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_array(key, value)\n",
      "/Users/szkhome/.pyenv/versions/anaconda3-4.3.0/lib/python3.6/site-packages/pandas/core/generic.py:3295: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "text['Review Text'][0]\n",
    "text[text['Review Text']==\"\"]=np.NaN\n",
    "text['Review Text'].fillna(\"No Review\",inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TrainとValidationとTestに分ける"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "トータルの行数は  train: 17084 and val_candidates: 6402\n"
     ]
    }
   ],
   "source": [
    "split = np.random.randn(len(text)) <0.6\n",
    "train = text[split]\n",
    "val_candidates = text[~split]\n",
    "print(\"トータルの行数は  train:\",len(train),\"and val_candidates:\",len(val_candidates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "トータルの行数は  validation: 4408 and test: 1994\n"
     ]
    }
   ],
   "source": [
    "split = np.random.randn(len(val_candidates)) <0.5\n",
    "validation = val_candidates[split]\n",
    "test = val_candidates[~split]\n",
    "print(\"トータルの行数は  validation:\",len(validation),\"and test:\",len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 前処理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここまでは、Dataframeに入っていますので、arrayに直します。\n",
    "\n",
    "\n",
    "またリストに入っていますので行にまとめます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "文字列のリスト（配列）を連結・結合: join()。文字列メソッドjoin()を使うと、文字列のリストを一つの文字列に連結することができる。\n",
    "\n",
    "書き方は以下の通り。\n",
    "\n",
    "- 間に挿入する文字列'.join([連結したい文字列のリスト])\n",
    "- 間に挿入する文字列'でjoin()メソッドを呼び出し、引数として[連結したい文字列のリスト]を渡す。\n",
    "\n",
    "空文字列を使えば[連結したい文字列のリスト]が単純連結されるし、カンマ,を使えばカンマ区切りの文字列となり、改行文字\\nを使えば文字列要素ごとに改行される。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 行をまとめる、正規表現を使っていらない文字を消す。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.arrayにする\n",
    "train=np.array(train)\n",
    "train=str(train)\n",
    "\n",
    "validation=np.array(validation)\n",
    "validation=str(validation)\n",
    "\n",
    "test=np.array(test)\n",
    "test=str(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# joinによって１行にする\n",
    "train = ''.join(train)\n",
    "validation = ''.join(validation)\n",
    "test = ''.join(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review データの変換をする\n",
    "\n",
    "def review_prepare(review):\n",
    "    review = review.lower()# lowercase text\n",
    "    review = re.sub(REPLACE_BY_SPACE_RE,\" \",review)# replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    review = re.sub(BAD_SYMBOLS_RE,\"\",review)# delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "    review = re.sub(' +',' ',review)\n",
    "    #review = \" \".join([word for word in review.split() if word not in STOPWORDS]) # delete stopwords from text\n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=review_prepare(train)\n",
    "validation=review_prepare(validation)\n",
    "test=review_prepare(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = [review_prepare(train) for train in reviews]\n",
    "# validation = [review_prepare(validation) for train in reviews]\n",
    "# test = [review_prepare(test) for train in reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' absolutely wonderful silky and sexy and comfortable love this dress its sooo pretty i happened to find it in a store and im glad i did bc i never would have ordered it online bc its petite i bought a petite and am 58 i love the length on me hits just a little below the knee would definitely be a true midi on someone who is truly petite i had such high hopes for this dress and really wanted it to work for me i initially ordered the petite small my usual size but i found this to be outrageously small so small in fact that i could not zip it up i reordered it in petite medium which was just ok overall the top half was comfortable and fit nicely but the bottom half had a very tight under layer and several somewhat cheap net over layers imo a major design flaw was the net over layer sewn directly into the zipper it c i was very happy to snag this dress at such a great price its very easy to slip on and has a very flattering cut and color combo this fit well but the top was very see through this never would have worked for me im glad i was able to try it on in the store and didnt order it online with different fabric it would have been great this dress in a lovely platinum is feminine and fits perfectly easy to wear and comfy too highly recommend '"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前処理をする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 前処理をする\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = text.replace('.', ' .')\n",
    "    words = text.split(' ')\n",
    "\n",
    "    word_to_id = {}\n",
    "    id_to_word = {}\n",
    "    for word in words:\n",
    "        if word not in word_to_id:\n",
    "            new_id = len(word_to_id)\n",
    "            word_to_id[word] = new_id\n",
    "            id_to_word[new_id] = word\n",
    "\n",
    "    corpus = np.array([word_to_id[w] for w in words])\n",
    "\n",
    "    return corpus, word_to_id, id_to_word\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習データの読み込み\n",
    "corpus, word_to_id, id_to_word = preprocess(train)\n",
    "corpus_val, _, _ = preprocess(validation)\n",
    "corpus_test, _, _ = preprocess(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def maeshori3(data):\n",
    "#     gyou = []\n",
    "#     word_to_ids =[]\n",
    "#     id_to_words =[]\n",
    "#     length=len(data[:10])\n",
    "#     for i in range(length):\n",
    "\n",
    "#         text=data[:10][i][0]\n",
    "#         text = text.lower()\n",
    "#         text = text.replace('.', ' .')\n",
    "#         words = text.split(' ')\n",
    "\n",
    "#         word_to_id = {}\n",
    "#         id_to_word = {}\n",
    "\n",
    "#         for word in words:\n",
    "#             if word not in word_to_id:\n",
    "#                 new_id = len(word_to_id)\n",
    "#                 word_to_id[word] = new_id\n",
    "#                 id_to_word[new_id] = word\n",
    "#         corpus = np.array([word_to_id[w] for w in words])\n",
    "#         gyou.append(corpus)\n",
    "#         word_to_ids.append(word_to_id)\n",
    "#         id_to_words.append(id_to_word)\n",
    "#     #print(gyou[0])\n",
    "#     return gyou, word_to_ids, id_to_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create_contexts_targetとは？(Target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_contexts_target(corpus, sliding_window_size=1):\n",
    "\n",
    "    target = corpus[sliding_window_size:-sliding_window_size]\n",
    "    contexts = []\n",
    "\n",
    "    for idx in range(sliding_window_size, len(corpus)-sliding_window_size):\n",
    "        cs = []\n",
    "        for t in range(-sliding_window_size, sliding_window_size + 1):\n",
    "            if t == 0:\n",
    "                continue\n",
    "            cs.append(corpus[idx + t])\n",
    "        contexts.append(cs)\n",
    "\n",
    "    return np.array(contexts), np.array(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts, target = create_contexts_target(corpus, sliding_window_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ところが、このデータはそもそもOne Hotにしないといけないので、OneHotします"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create_contexts_targetとは？(One-Hotするやつ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_one_hot(corpus, vocab_size):\n",
    "    N = corpus.shape[0]\n",
    "    if corpus.ndim == 1:\n",
    "        one_hot = np.zeros((N, vocab_size), dtype=np.int32)\n",
    "        for idx, word_id in enumerate(corpus):\n",
    "            one_hot[idx, word_id] = 1\n",
    "\n",
    "    elif corpus.ndim == 2:\n",
    "        C = corpus.shape[1]\n",
    "        one_hot = np.zeros((N, C, vocab_size), dtype=np.int32)\n",
    "        for idx_0, word_ids in enumerate(corpus):\n",
    "            for idx_1, word_id in enumerate(word_ids):\n",
    "                one_hot[idx_0, idx_1, word_id] = 1\n",
    "\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-Hotの前にVocabサイズを定義します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(word_to_id)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 1 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "target = convert_one_hot(target, vocab_size)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1 0 0 ... 0 0 0]\n",
      "  [0 0 1 ... 0 0 0]]\n",
      "\n",
      " [[0 1 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 1 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 1 0]]\n",
      "\n",
      " [[0 0 0 ... 1 0 0]\n",
      "  [0 0 0 ... 0 0 1]]\n",
      "\n",
      " [[0 0 0 ... 0 1 0]\n",
      "  [1 0 0 ... 0 0 0]]]\n"
     ]
    }
   ],
   "source": [
    "contexts = convert_one_hot(contexts, vocab_size)\n",
    "print(contexts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習させる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus, word_to_id, id_to_word = ptb.load_data('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2, ..., 39, 26, 24])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus, word_to_id, id_to_word = preprocess('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 1 |  iter 1 / 1327 | time 2[s] | perplexity 10000.18\n",
      "| epoch 1 |  iter 21 / 1327 | time 41[s] | perplexity 3448.01\n",
      "| epoch 1 |  iter 41 / 1327 | time 75[s] | perplexity 1531.92\n",
      "| epoch 1 |  iter 61 / 1327 | time 110[s] | perplexity 1335.89\n",
      "| epoch 1 |  iter 81 / 1327 | time 144[s] | perplexity 1073.28\n",
      "| epoch 1 |  iter 101 / 1327 | time 178[s] | perplexity 814.40\n",
      "| epoch 1 |  iter 121 / 1327 | time 212[s] | perplexity 783.82\n",
      "| epoch 1 |  iter 141 / 1327 | time 245[s] | perplexity 710.51\n",
      "| epoch 1 |  iter 161 / 1327 | time 282[s] | perplexity 677.42\n",
      "| epoch 1 |  iter 181 / 1327 | time 320[s] | perplexity 652.97\n",
      "| epoch 1 |  iter 201 / 1327 | time 357[s] | perplexity 575.03\n",
      "| epoch 1 |  iter 221 / 1327 | time 396[s] | perplexity 568.48\n",
      "| epoch 1 |  iter 241 / 1327 | time 433[s] | perplexity 514.76\n",
      "| epoch 1 |  iter 261 / 1327 | time 467[s] | perplexity 528.19\n",
      "| epoch 1 |  iter 281 / 1327 | time 503[s] | perplexity 515.25\n",
      "| epoch 1 |  iter 301 / 1327 | time 538[s] | perplexity 437.18\n",
      "| epoch 1 |  iter 321 / 1327 | time 575[s] | perplexity 393.34\n",
      "| epoch 1 |  iter 341 / 1327 | time 613[s] | perplexity 449.33\n",
      "| epoch 1 |  iter 361 / 1327 | time 650[s] | perplexity 456.64\n",
      "| epoch 1 |  iter 381 / 1327 | time 683[s] | perplexity 385.71\n",
      "| epoch 1 |  iter 401 / 1327 | time 717[s] | perplexity 404.26\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-ab3c7ca9b592>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     trainer.fit(xs, ts, max_epoch=1, batch_size=batch_size,\n\u001b[0;32m---> 46\u001b[0;31m                 time_size=time_size, max_grad=max_grad)\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/diveintocode-term0/sprint23/common/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, xs, ts, max_epoch, batch_size, time_size, max_grad, eval_interval)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0;31m# 勾配を求め、パラメータを更新\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_duplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 共有された重みを1つに集約\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/diveintocode-term0/sprint23/better_rnnlm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, xs, ts, train_flg)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_flg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_flg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/diveintocode-term0/sprint23/better_rnnlm.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, xs, train_flg)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/diveintocode-term0/sprint23/common/time_layers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0mrx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from common import config\n",
    "from common.optimizer import SGD\n",
    "from common.trainer import RnnlmTrainer\n",
    "from common.util import eval_perplexity, to_gpu\n",
    "from dataset import ptb\n",
    "from better_rnnlm import BetterRnnlm\n",
    "\n",
    "\n",
    "# ハイパーパラメータの設定\n",
    "batch_size = 20\n",
    "wordvec_size = 650\n",
    "hidden_size = 650\n",
    "time_size = 35\n",
    "lr = 20.0\n",
    "max_epoch = 40\n",
    "max_grad = 0.25\n",
    "dropout = 0.5\n",
    "\n",
    "# 学習データの読み込み\n",
    "# corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "# corpus_val, _, _ = ptb.load_data('val')\n",
    "# corpus_test, _, _ = ptb.load_data('test')\n",
    "corpus, word_to_id, id_to_word = preprocess('train')\n",
    "corpus_val, _, _ = preprocess('val')\n",
    "corpus_test, _, _ = preprocess('test')\n",
    "\n",
    "if config.GPU:\n",
    "    corpus = to_gpu(corpus)\n",
    "    corpus_val = to_gpu(corpus_val)\n",
    "    corpus_test = to_gpu(corpus_test)\n",
    "\n",
    "vocab_size = len(word_to_id)\n",
    "xs = corpus[:-1]\n",
    "ts = corpus[1:]\n",
    "\n",
    "model = BetterRnnlm(vocab_size, wordvec_size, hidden_size, dropout)\n",
    "optimizer = SGD(lr)\n",
    "trainer = RnnlmTrainer(model, optimizer)\n",
    "\n",
    "best_ppl = float('inf')\n",
    "for epoch in range(max_epoch):\n",
    "    trainer.fit(xs, ts, max_epoch=1, batch_size=batch_size,\n",
    "                time_size=time_size, max_grad=max_grad)\n",
    "\n",
    "    model.reset_state()\n",
    "    ppl = eval_perplexity(model, corpus_val)\n",
    "    print('valid perplexity: ', ppl)\n",
    "\n",
    "    if best_ppl > ppl:\n",
    "        best_ppl = ppl\n",
    "        model.save_params()\n",
    "    else:\n",
    "        lr /= 4.0\n",
    "        optimizer.lr = lr\n",
    "\n",
    "    model.reset_state()\n",
    "    print('-' * 50)\n",
    "\n",
    "\n",
    "# テストデータでの評価\n",
    "model.reset_state()\n",
    "ppl_test = eval_perplexity(model, corpus_test)\n",
    "print('test perplexity: ', ppl_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating perplexity ...\n",
      "234 / 235\n",
      "test perplexity:  347.21979707705606\n"
     ]
    }
   ],
   "source": [
    "# テストデータでの評価\n",
    "model.reset_state()\n",
    "ppl_test = eval_perplexity(model, corpus_test)\n",
    "print('test perplexity: ', ppl_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "280.1875px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
