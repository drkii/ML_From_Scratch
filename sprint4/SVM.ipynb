{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM From Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本SVMスクラッチは、２つのものを行うことで普段使う数式レベルからの理解に挑戦する。\n",
    "- ハードマージンSVM：数式のみで解き、得られたSVM式に、新たな情報が代入されたら正負を判定できるものにする\n",
    "- ソフトマージンSVM：実装を行う。特にコスト関数と、Gradient Decentを使って小さくなっていることを確認できることを目標とする\n",
    "\n",
    "\n",
    "ハードマージンSVMでは、実際にそう当てはまる事象がそう多くない。\n",
    "\n",
    "理由として全ての訓練事例が正確に分類されなければならないという制約を前提にしているからである。\n",
    "\n",
    "つまり、先の線形関数で分離できない場合は、制約を満たす解がそもそも存在しなくなってしまう。\n",
    "\n",
    "そのため、実装はより実践的で数式実装の訓練となるソフトマージンが選ばれた。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$ D={(x[0], -1), (x[1]) ,1)}$\n",
    "に対して、SVMを構築する。ただし、以下のデータセットが与えられている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1156f2b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#2個のSamples\n",
    "X=np.zeros((2,2))\n",
    "X[0]=[0,1]\n",
    "X[1]=[1,1]\n",
    "\n",
    "plt.figure(figsize =(12,8))\n",
    "plt.scatter(X[0], X[1], marker='o', s=50)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 厳密制約：ハードマージンSVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 求める式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このハードマージンSVMにかく数式については解説はしていない\n",
    "\n",
    "\n",
    "「言語処理のための機械学習入門」の式を用いて、2値の2クラス分類を行うものである。\n",
    "\n",
    "\n",
    "y(i) = +1であるようなトレーニング事例については、\n",
    "\n",
    "wx(i) -b >= 1であればよく、\n",
    "\n",
    "y(i) = -1であるようなトレーニング事例については、\n",
    "\n",
    "wx(i) -b >= -1であればよい。\n",
    "\n",
    "\n",
    "この二つの条件はつぎのようにまとめて表せる\n",
    "\n",
    "\n",
    "y(i)(wx(i) -b) >=1\n",
    "\n",
    "\n",
    "このことより、求める対象の式\n",
    "\n",
    "f(x) = w*x-b\n",
    "\n",
    "\n",
    "と置くことができる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVMの式から求められるものを先に計算する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "求める式を　f(x) = w*x-bと置くと、\n",
    "\n",
    "まず、以下であることがわかる\n",
    "\n",
    "\n",
    "$x[0]*x[0] = 1$\n",
    "\n",
    "\n",
    "$x[1]*x[1] = 2$\n",
    "\n",
    "\n",
    "$x[0]*x[1] = x[1]*x[0] = 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 不等式制約つき最適化問題を解く"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "双対ラグランジュ関数を用いる。\n",
    "\n",
    "\n",
    "ラグランジュ乗数αi (>=0)を導入すると、ラグランジュ関数で表わせ、鞍点理論より、ラグランジュ関数を最大化するαiを求めればよいことがわかる\n",
    "\n",
    "\n",
    "ここでの最大化問題は、この関数においては、双対問題ともいわれ、それは双対ラグランジュ関数を解くことであるとのこと。\n",
    "\n",
    "\n",
    "つまり、ここではαが二つの最適化問題をとくことになり、双対ラグランジュ関数は以下となる。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$L(w, b, α1, α2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 代入計算式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " -1/2{α1α1 * (-1) * (-1) * 1 + α2α2 * 1* 1* 2 + α1α2 * (-1)* (1)* 1 + α2α1* 1* (-1) * 1} + α1 + α2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### まとめると"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-1/2α1** 2 -α2** 2 + α1α2 + α1 +α2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここで、α1* (-1) + α2 *1 = 0より、"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$L(w, b, α1, α2)　= -1/2*α1**2 + 2α1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "したがって、微分すると、"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-α1+2になるので"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これを０とすると、$α1 = α2 = 2$  が得られた。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここに、X[1]=[1,1]を用いて、"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b = 2 * (-1) * (0, 1) (1,1) +2 *1 *(1,1)(1,1) -1 =1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分離平面は、bとして、１が得られた。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここでは、分離平面は、w*x = bとなる点xの集合となる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここで、wも求めておく、"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "w = 2*(-1)*(0,1) + 2 * 1 *(1,1) = (2,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 得られたSVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$f(x) = (2, 0)*x-1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "が得られた。つまりこの式が０以上ならば正のクラスに、そうでなければ負のクラスに分類される。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### このSVMの使い方"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x(1,0)を分類する場合、\n",
    "$f(x) = (2, 0)*(1, 0)-1 = 1 > 0$\n",
    "\n",
    "このx(1,0)は正の例となる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この例で得られたように、ハードマージンSVMは導出もそれほど難しくない。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 緩和制約：ソフトマージンSVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上の導出したSVMでは、実際のデータにはなかなかうまく動かない。\n",
    "\n",
    "理由として全ての訓練事例が正確に分類されなければならないという制約を前提にしているからである。\n",
    "\n",
    "つまり、先の線形関数で分離できない場合は、制約を満たす解がそもそも存在しなくなってしまう。\n",
    "\n",
    "そこで、8/11の朝から学んだように、以下のようなソフトマージンSVMがあるので、こちらで実装する。\n",
    "\n",
    "http://cs231n.github.io/linear-classify/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [[0,1],[1, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 4],\n",
       "       [1, 2]])"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2Dと２Classを前提にしているので、2行２列の重みがあると想定する。\n",
    "\n",
    "\n",
    "W = np.array([[2,4],[1,2]])\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 6],\n",
       "       [2, 3]])"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# s0, s1までだす=内積\n",
    "s = np.dot(W, x)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "#適当にDeltaをとっておきます\n",
    "delta = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 関数　margin_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "def margin_sum(x, W, delta):\n",
    "    x = np.array(x)\n",
    "    W = np.array(W)\n",
    "    s = np.dot(W, x)\n",
    "    margin_sum = 0\n",
    "    for i in range(W.shape[0]):\n",
    "        if i == 1:\n",
    "            continue\n",
    "        margin = max(0, s[0][i] - s[0][1] + delta)\n",
    "        margin_sum += margin\n",
    "\n",
    "    return margin_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[0,1],[1, 1]])\n",
    "W = np.array([[1,2],[-1,1]])\n",
    "delta = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "margin_sum(x, W, delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Decent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X[0,:][:, np.newaxis].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_loss_naive(W, x, y, reg):\n",
    "    dW = np.zeros(W.shape) \n",
    "  \n",
    "    # ロスと勾配を計算 \n",
    "    num_classes = W.shape[1]\n",
    "    num_train = X.shape[0]\n",
    "    loss = 0.0\n",
    "    for i in range(num_train):\n",
    "        scores = X[i,:].dot(W)\n",
    "        #print(scores)\n",
    "        correct_class_score = scores[y[i]]\n",
    "        #print(correct_class_score)\n",
    "        for j in range(num_classes):\n",
    "            if j == y[i]:\n",
    "                continue\n",
    "            margin_sum = scores[j] - correct_class_score + 1 \n",
    "            if margin_sum > 0:\n",
    "                loss += margin_sum\n",
    "                #print(dW[:,y[i]].shape)\n",
    "                #print(X[i,:].shape)\n",
    "                dW[:,y[i]] -= X[i,:][:, np.newaxis]\n",
    "                dW[:,j] += X[i,:]\n",
    "\n",
    "    # Averaging over all examples\n",
    "    loss /= num_train\n",
    "    dW /= num_train\n",
    "\n",
    "    # Add regularization\n",
    "    loss += 0.5 * reg * np.sum(W * W)\n",
    "    dW += reg*W\n",
    "    # Wを新しくする\n",
    "    W = W - dW\n",
    "\n",
    "    return loss, dW, W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = 0.01\n",
    "y = np.array([[-1],[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.535]), array([[ 0.01,  0.02],\n",
       "        [-0.01,  0.01]]), array([[ 0.99,  1.98],\n",
       "        [-0.99,  0.99]]))"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_loss_naive(W, x, y, reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "202.796875px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
